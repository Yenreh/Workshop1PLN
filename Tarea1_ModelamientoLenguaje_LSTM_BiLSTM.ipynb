{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taller 1: Aplicación de RNNs al Modelamiento de Lenguaje en Español (LSTM/BiLSTM)\n",
    "\n",
    "**Curso:** PLN\n",
    "**Objetivo:** Experimentar con modelos de Redes Neuronales Recurrentes (RNNs), específicamente LSTM y BiLSTM, para el modelado del lenguaje en español. \n",
    "**Autor:** Herney Eduardo Quintero Trochez  \n",
    "**Fecha:** 2025  \n",
    "**Universidad:** Universidad Del Valle  \n",
    "**Curso:** Procesamiento de Lenguaje Natural (PLN) - Taller 1\n",
    "## Componentes implementados:\n",
    "1. Carga del Dataset (`spanish_billion_words_clean`)\n",
    "2. Tokenización y Creación del Vocabulario\n",
    "3. Creación del Conjunto de Entrenamiento (X, Y)\n",
    "4. Padding y Truncado (MAX_LEN ≤ 50)\n",
    "5. División del Conjunto (Train/Test 80%/20%)\n",
    "6. Construcción del Modelo LSTM/BiLSTM\n",
    "7. Entrenamiento con Early Stopping\n",
    "8. Cálculo de la Perplejidad\n",
    "9. Predicción de la Próxima Palabra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Configuración de Parámetros Globales\n",
    "\n",
    "Esta sección permite modificar fácilmente todos los parámetros del modelo para experimentar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuración cargada:\n",
      "- Modelo: BiLSTM\n",
      "- Dataset: 50,000 muestras de jhonparra18/spanish_billion_words_clean\n"
     ]
    }
   ],
   "source": [
    "# Dataset configuration\n",
    "DATASET_NAME = \"jhonparra18/spanish_billion_words_clean\"\n",
    "DATASET_SPLIT = \"train\"\n",
    "DATASET_STREAMING = True\n",
    "DATASET_TAKE = 50000  # Número de ejemplos a tomar del dataset\n",
    "MIN_WORDS_PER_SENTENCE = 4  # Filtro: oraciones con al menos N palabras\n",
    "OOV_TOKEN = \"<OOV>\"  # Token para palabras fuera del vocabulario\n",
    "\n",
    "# Model architecture parameters\n",
    "EMBEDDING_DIM = 300  # Dimensión del embedding de palabras\n",
    "LSTM_UNITS = 128 # Número de unidades en las capas LSTM\n",
    "DENSE_UNITS = 128  # Número de unidades en la capa densa intermedia\n",
    "USE_BIDIRECTIONAL = True  # Usar BiLSTM en lugar de LSTM unidireccional\n",
    "\n",
    "# Training parameters\n",
    "EPOCHS = 30  # Número de épocas de entrenamiento\n",
    "BATCH_SIZE = 512  # Tamaño del batch\n",
    "VALIDATION_SPLIT = 0.2  # Porcentaje de datos para validación\n",
    "LEARNING_RATE = 0.001  # Tasa de aprendizaje\n",
    "PATIENCE = 15  # Paciencia para early stopping\n",
    "DROPOUT_RATE = 0.2  # Tasa de out para regularización\n",
    "\n",
    "# Sequence processing\n",
    "PADDING_TYPE = 'pre'  # Tipo de padding: 'pre' o 'post'\n",
    "\n",
    "# Output parameters\n",
    "VERBOSE_TRAINING = 1  # Nivel de verbose durante entrenamiento\n",
    "VERBOSE_PREDICTION = 0  # Nivel de verbose durante predicción\n",
    "\n",
    "print(f\"Configuración cargada:\")\n",
    "print(f\"- Modelo: {'BiLSTM' if USE_BIDIRECTIONAL else 'LSTM'}\")\n",
    "print(f\"- Dataset: {DATASET_TAKE:,} muestras de {DATASET_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importación de Librerías\n",
    "\n",
    "Se importan todas las librerías necesarias para el proyecto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-26 00:55:05.730020: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-26 00:55:05.770471: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-26 00:55:06.672770: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "/home/yenreh/anaconda3/envs/py310ia/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Librerías importadas exitosamente!\n",
      "TensorFlow version: 2.20.0\n",
      "GPU detectada: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Bidirectional\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import load_dataset\n",
    "import json\n",
    "import os\n",
    "\n",
    "print(\"Librerías importadas exitosamente!\")\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    print(f\"GPU detectada: {gpus}\")\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "else:\n",
    "    print(\"No se detectó GPU, usando CPU.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Carga del Dataset\n",
    "\n",
    "Se carga el dataset `spanish_billion_words_clean` de Hugging Face y se filtran oraciones muy cortas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando dataset...\n",
      "Total de oraciones cargadas: 50000\n",
      "\n",
      "Ejemplos de oraciones:\n",
      "1. source wikisource librodot com sentido y sensibilidad jane austen capitulo i\n",
      "2. la familia dashwood llevaba largo tiempo afincada en sussex\n",
      "3. su propiedad era de buen tamaño y en el centro de ella se encontraba la residencia norland park donde la manera tan digna en que habían vivido por muchas generaciones llegó a granjearles el respeto de todos los conocidos del lugar\n",
      "4. el último dueño de esta propiedad había sido un hombre soltero que alcanzó una muy avanzada edad y que durante gran parte de su existencia tuvo en su hermana una fiel compañera y ama de casa\n",
      "5. pero la muerte de ella ocurrida diez años antes que la suya produjo grandes alteraciones en su hogar\n"
     ]
    }
   ],
   "source": [
    "print(\"Cargando dataset...\")\n",
    "dataset = load_dataset(DATASET_NAME, split=DATASET_SPLIT, streaming=DATASET_STREAMING).take(DATASET_TAKE)\n",
    "sentences = [example['text'] for example in dataset if len(example['text'].split()) >= MIN_WORDS_PER_SENTENCE]\n",
    "\n",
    "print(f\"Total de oraciones cargadas: {len(sentences)}\")\n",
    "print(\"\\nEjemplos de oraciones:\")\n",
    "for i, sentence in enumerate(sentences[:5]):\n",
    "    print(f\"{i+1}. {sentence}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Tokenización y Creación del Vocabulario\n",
    "\n",
    "Se Tokenizan las oraciones y se crea el vocabulario con mapeo palabra→índice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulario: 63944 palabras\n",
      "\n",
      "Primeras 10 palabras del vocabulario:\n",
      "<OOV> → 1\n",
      "de → 2\n",
      "y → 3\n",
      "que → 4\n",
      "la → 5\n",
      "el → 6\n",
      "en → 7\n",
      "a → 8\n",
      "digito → 9\n",
      "los → 10\n",
      "\n",
      "Ejemplo de tokenización:\n",
      "Oración: source wikisource librodot com sentido y sensibilidad jane austen capitulo i\n",
      "Secuencia: [9287, 33752, 33753, 357, 687, 3, 4459, 423, 33754, 9288, 529]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(oov_token=OOV_TOKEN)  # Token para palabras desconocidas\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "\n",
    "# Convertir frases a secuencias numéricas\n",
    "sequences = tokenizer.texts_to_sequences(sentences)\n",
    "\n",
    "# Tamaño del vocabulario\n",
    "vocab_size = len(tokenizer.word_index) + 1  # +1 por el padding (índice 0)\n",
    "print(f\"Vocabulario: {vocab_size} palabras\")\n",
    "\n",
    "print(\"\\nPrimeras 10 palabras del vocabulario:\")\n",
    "for i, (word, idx) in enumerate(list(tokenizer.word_index.items())[:10]):\n",
    "    print(f\"{word} → {idx}\")\n",
    "\n",
    "print(f\"\\nEjemplo de tokenización:\")\n",
    "example_sentence = sentences[0]\n",
    "example_sequence = sequences[0]\n",
    "print(f\"Oración: {example_sentence}\")\n",
    "print(f\"Secuencia: {example_sequence}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Creación del Conjunto de Entrenamiento (X, Y)\n",
    "\n",
    "Para cada secuencia `[w1, w2, ..., wn]`, se crean pares:\n",
    "- `(w1) → w2`\n",
    "- `(w1, w2) → w3`\n",
    "- `...`\n",
    "- `(w1, ..., wn-1) → wn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de secuencias de entrenamiento generadas: 1194314\n",
      "\n",
      "Ejemplos de secuencias X → y:\n",
      "['source'] → wikisource\n",
      "['source', 'wikisource'] → librodot\n",
      "['source', 'wikisource', 'librodot'] → com\n",
      "['source', 'wikisource', 'librodot', 'com'] → sentido\n",
      "['source', 'wikisource', 'librodot', 'com', 'sentido'] → y\n"
     ]
    }
   ],
   "source": [
    "X = []  # Secuencias de entrada: [palabra1], [palabra1, palabra2], ...\n",
    "y = []  # Palabra siguiente (objetivo)\n",
    "\n",
    "for seq in sequences:\n",
    "    for i in range(len(seq) - 1):\n",
    "        X.append(seq[:i+1])    # Desde el inicio hasta la palabra actual\n",
    "        y.append(seq[i+1])     # La siguiente palabra\n",
    "\n",
    "print(f\"Total de secuencias de entrenamiento generadas: {len(X)}\")\n",
    "print(\"\\nEjemplos de secuencias X → y:\")\n",
    "for i in range(5):\n",
    "    # Convertir índices a palabras para mostrar\n",
    "    x_words = [tokenizer.index_word.get(idx, '<UNK>') for idx in X[i]]\n",
    "    y_word = tokenizer.index_word.get(y[i], '<UNK>')\n",
    "    print(f\"{x_words} → {y_word}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Padding y Truncado (MAX_LEN ≤ 50)\n",
    "\n",
    "Se Aplica padding a las secuencias y se trunca si la longitud máxima excede 50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longitud máxima encontrada: 321\n",
      "MAX_LEN aplicado (truncado a 50): 50\n",
      "\n",
      "Forma de X_padded: (1194314, 50)\n",
      "Forma de y: (1194314,)\n",
      "\n",
      "Ejemplo de X_padded (primeras 3 secuencias):\n",
      "[[    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0  9287]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "   9287 33752]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0  9287\n",
      "  33752 33753]]\n",
      "\n",
      "Ejemplo de y (primeras 10 etiquetas):\n",
      "[33752 33753   357   687     3  4459   423 33754  9288   529]\n"
     ]
    }
   ],
   "source": [
    "# Longitud máxima de las secuencias (con restricción MAX_LEN <= 50)\n",
    "raw_max_length = max([len(seq) for seq in X])\n",
    "MAX_LEN = min(50, raw_max_length)  # Aplicar restricción de máximo 50\n",
    "print(f\"Longitud máxima encontrada: {raw_max_length}\")\n",
    "print(f\"MAX_LEN aplicado (truncado a 50): {MAX_LEN}\")\n",
    "\n",
    "# Aplicar padding y truncado a las secuencias de entrada\n",
    "X_padded = pad_sequences(X, maxlen=MAX_LEN, padding=PADDING_TYPE, truncating='pre')\n",
    "y = np.array(y)  # Etiquetas: ya es un array 1D\n",
    "\n",
    "print(f\"\\nForma de X_padded: {X_padded.shape}\")  # (número de muestras, MAX_LEN)\n",
    "print(f\"Forma de y: {y.shape}\")\n",
    "print(\"\\nEjemplo de X_padded (primeras 3 secuencias):\")\n",
    "print(X_padded[:3])\n",
    "print(\"\\nEjemplo de y (primeras 10 etiquetas):\")\n",
    "print(y[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. División del Conjunto (Train/Test: 80%/20%)\n",
    "\n",
    "Se dividen los datos en conjuntos de entrenamiento y prueba usando `train_test_split`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "División del conjunto:\n",
      "X_train: (955451, 50), y_train: (955451,)\n",
      "X_test: (238863, 50), y_test: (238863,)\n",
      "\n",
      "Porcentajes:\n",
      "Entrenamiento: 80.0%\n",
      "Prueba: 20.0%\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_padded, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "print(f\"División del conjunto:\")\n",
    "print(f\"X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
    "print(f\"X_test: {X_test.shape}, y_test: {y_test.shape}\")\n",
    "print(f\"\\nPorcentajes:\")\n",
    "print(f\"Entrenamiento: {len(X_train)/(len(X_train)+len(X_test))*100:.1f}%\")\n",
    "print(f\"Prueba: {len(X_test)/(len(X_train)+len(X_test))*100:.1f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Construcción del Modelo LSTM/BiLSTM\n",
    "\n",
    "Se crea el modelo con arquitectura configurable (LSTM o BiLSTM) y se compila con `sparse_categorical_crossentropy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yenreh/anaconda3/envs/py310ia/lib/python3.10/site-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1758866120.944276  359937 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9607 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)        │    <span style=\"color: #00af00; text-decoration-color: #00af00\">19,183,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_lstm              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">439,296</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_hidden (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63944</span>)          │     <span style=\"color: #00af00; text-decoration-color: #00af00\">8,248,776</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m300\u001b[0m)        │    \u001b[38;5;34m19,183,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_lstm              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m439,296\u001b[0m │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_hidden (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63944\u001b[0m)          │     \u001b[38;5;34m8,248,776\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">27,904,168</span> (106.45 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m27,904,168\u001b[0m (106.45 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">27,904,168</span> (106.45 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m27,904,168\u001b[0m (106.45 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_model(vocab_size, max_length):\n",
    "    \"\"\"\n",
    "    Crea un modelo de lenguaje usando BiLSTM o LSTM según configuración.\n",
    "    \n",
    "    Args:\n",
    "        vocab_size (int): Tamaño del vocabulario\n",
    "        max_length (int): Longitud máxima de las secuencias\n",
    "    \n",
    "    Returns:\n",
    "        tensorflow.keras.Model: Modelo compilado\n",
    "    \"\"\"\n",
    "    model = Sequential([\n",
    "        Embedding(vocab_size, EMBEDDING_DIM, input_length=max_length, name='embedding'),\n",
    "        # Usar BiLSTM si está habilitado, sino LSTM unidireccional\n",
    "        Bidirectional(LSTM(LSTM_UNITS, name='lstm'), name='bidirectional_lstm') if USE_BIDIRECTIONAL \n",
    "        else LSTM(LSTM_UNITS, name='lstm'),\n",
    "        Dropout(DROPOUT_RATE, name='dropout'),\n",
    "        Dense(DENSE_UNITS, activation='relu', name='dense_hidden'),\n",
    "        Dense(vocab_size, activation='softmax', name='output')  # Probabilidades para cada palabra\n",
    "    ])\n",
    "    \n",
    "    # Configurar optimizador con tasa de aprendizaje personalizada\n",
    "    optimizer = Adam(learning_rate=LEARNING_RATE)\n",
    "    \n",
    "    # Usar sparse_categorical_crossentropy (NO necesita one-hot encoding)\n",
    "    model.compile(\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        optimizer=optimizer,\n",
    "        metrics=['accuracy', 'sparse_top_k_categorical_accuracy']\n",
    "    )\n",
    "    \n",
    "    model.build(input_shape=(None, max_length))\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = create_model(vocab_size, MAX_LEN)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Entrenamiento del Modelo con Early Stopping\n",
    "\n",
    "Se entrena el modelo con Early Stopping para prevenir overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando el modelo BiLSTM...\n",
      "Arquitectura: 300D embedding → Bi-LSTM(128) → Dense(128) → Softmax(63944)\n",
      "Parámetros de entrenamiento: 30 epochs, batch_size=512, lr=0.001, dropout=0.2\n",
      "Early Stopping habilitado: val_loss con patience=15\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-26 00:55:22.969794: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:473] Loaded cuDNN version 91300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1493/1493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.0769 - loss: 7.4081 - sparse_top_k_categorical_accuracy: 0.2080\n",
      "Epoch 1: val_loss improved from None to 6.47657, saving model to models/BiLSTM_emb300_take50000.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1493/1493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 88ms/step - accuracy: 0.0961 - loss: 6.9601 - sparse_top_k_categorical_accuracy: 0.2399 - val_accuracy: 0.1265 - val_loss: 6.4766 - val_sparse_top_k_categorical_accuracy: 0.2818\n",
      "Epoch 2/30\n",
      "\u001b[1m1493/1493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.1320 - loss: 6.2093 - sparse_top_k_categorical_accuracy: 0.2894\n",
      "Epoch 2: val_loss improved from 6.47657 to 6.17850, saving model to models/BiLSTM_emb300_take50000.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1493/1493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 88ms/step - accuracy: 0.1366 - loss: 6.1336 - sparse_top_k_categorical_accuracy: 0.2953 - val_accuracy: 0.1437 - val_loss: 6.1785 - val_sparse_top_k_categorical_accuracy: 0.3059\n",
      "Epoch 3/30\n",
      "\u001b[1m1493/1493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.1574 - loss: 5.7385 - sparse_top_k_categorical_accuracy: 0.3199\n",
      "Epoch 3: val_loss improved from 6.17850 to 6.03425, saving model to models/BiLSTM_emb300_take50000.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1493/1493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 88ms/step - accuracy: 0.1595 - loss: 5.7089 - sparse_top_k_categorical_accuracy: 0.3235 - val_accuracy: 0.1589 - val_loss: 6.0343 - val_sparse_top_k_categorical_accuracy: 0.3233\n",
      "Epoch 4/30\n",
      "\u001b[1m1493/1493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.1768 - loss: 5.4035 - sparse_top_k_categorical_accuracy: 0.3433\n",
      "Epoch 4: val_loss improved from 6.03425 to 5.98015, saving model to models/BiLSTM_emb300_take50000.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1493/1493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 87ms/step - accuracy: 0.1778 - loss: 5.3963 - sparse_top_k_categorical_accuracy: 0.3448 - val_accuracy: 0.1683 - val_loss: 5.9801 - val_sparse_top_k_categorical_accuracy: 0.3344\n",
      "Epoch 5/30\n",
      "\u001b[1m1493/1493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.1917 - loss: 5.1304 - sparse_top_k_categorical_accuracy: 0.3616\n",
      "Epoch 5: val_loss did not improve from 5.98015\n",
      "\u001b[1m1493/1493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 88ms/step - accuracy: 0.1914 - loss: 5.1383 - sparse_top_k_categorical_accuracy: 0.3613 - val_accuracy: 0.1738 - val_loss: 5.9925 - val_sparse_top_k_categorical_accuracy: 0.3410\n",
      "Epoch 6/30\n",
      "\u001b[1m1493/1493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.2040 - loss: 4.8938 - sparse_top_k_categorical_accuracy: 0.3771\n",
      "Epoch 6: val_loss did not improve from 5.98015\n",
      "\u001b[1m1493/1493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 88ms/step - accuracy: 0.2025 - loss: 4.9113 - sparse_top_k_categorical_accuracy: 0.3765 - val_accuracy: 0.1764 - val_loss: 6.0684 - val_sparse_top_k_categorical_accuracy: 0.3438\n",
      "Epoch 7/30\n",
      "\u001b[1m1493/1493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.2152 - loss: 4.6799 - sparse_top_k_categorical_accuracy: 0.3923\n",
      "Epoch 7: val_loss did not improve from 5.98015\n",
      "\u001b[1m1493/1493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 88ms/step - accuracy: 0.2138 - loss: 4.7035 - sparse_top_k_categorical_accuracy: 0.3913 - val_accuracy: 0.1787 - val_loss: 6.1957 - val_sparse_top_k_categorical_accuracy: 0.3470\n",
      "Epoch 8/30\n",
      "\u001b[1m1493/1493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.2266 - loss: 4.4768 - sparse_top_k_categorical_accuracy: 0.4072\n",
      "Epoch 8: val_loss did not improve from 5.98015\n",
      "\u001b[1m1493/1493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 88ms/step - accuracy: 0.2249 - loss: 4.5116 - sparse_top_k_categorical_accuracy: 0.4053 - val_accuracy: 0.1799 - val_loss: 6.3352 - val_sparse_top_k_categorical_accuracy: 0.3468\n",
      "Epoch 9/30\n",
      "\u001b[1m1493/1493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.2385 - loss: 4.2908 - sparse_top_k_categorical_accuracy: 0.4243\n",
      "Epoch 9: val_loss did not improve from 5.98015\n",
      "\u001b[1m1493/1493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 88ms/step - accuracy: 0.2357 - loss: 4.3330 - sparse_top_k_categorical_accuracy: 0.4203 - val_accuracy: 0.1797 - val_loss: 6.5083 - val_sparse_top_k_categorical_accuracy: 0.3444\n",
      "Epoch 10/30\n",
      "\u001b[1m1493/1493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.2517 - loss: 4.1199 - sparse_top_k_categorical_accuracy: 0.4414\n",
      "Epoch 10: val_loss did not improve from 5.98015\n",
      "\u001b[1m1493/1493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 88ms/step - accuracy: 0.2479 - loss: 4.1683 - sparse_top_k_categorical_accuracy: 0.4370 - val_accuracy: 0.1782 - val_loss: 6.7413 - val_sparse_top_k_categorical_accuracy: 0.3411\n",
      "Epoch 11/30\n",
      "\u001b[1m1493/1493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.2642 - loss: 3.9675 - sparse_top_k_categorical_accuracy: 0.4608\n",
      "Epoch 11: val_loss did not improve from 5.98015\n",
      "\u001b[1m1493/1493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 88ms/step - accuracy: 0.2604 - loss: 4.0165 - sparse_top_k_categorical_accuracy: 0.4553 - val_accuracy: 0.1774 - val_loss: 6.9845 - val_sparse_top_k_categorical_accuracy: 0.3385\n",
      "Epoch 12/30\n",
      "\u001b[1m1493/1493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.2791 - loss: 3.8225 - sparse_top_k_categorical_accuracy: 0.4791\n",
      "Epoch 12: val_loss did not improve from 5.98015\n",
      "\u001b[1m1493/1493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 88ms/step - accuracy: 0.2735 - loss: 3.8793 - sparse_top_k_categorical_accuracy: 0.4725 - val_accuracy: 0.1766 - val_loss: 7.1792 - val_sparse_top_k_categorical_accuracy: 0.3348\n",
      "Epoch 13/30\n",
      "\u001b[1m1493/1493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.2945 - loss: 3.6879 - sparse_top_k_categorical_accuracy: 0.4977\n",
      "Epoch 13: val_loss did not improve from 5.98015\n",
      "\u001b[1m1493/1493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 88ms/step - accuracy: 0.2866 - loss: 3.7526 - sparse_top_k_categorical_accuracy: 0.4891 - val_accuracy: 0.1725 - val_loss: 7.4053 - val_sparse_top_k_categorical_accuracy: 0.3270\n",
      "Epoch 14/30\n",
      "\u001b[1m1493/1493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.3068 - loss: 3.5751 - sparse_top_k_categorical_accuracy: 0.5132\n",
      "Epoch 14: val_loss did not improve from 5.98015\n",
      "\u001b[1m1493/1493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 88ms/step - accuracy: 0.2998 - loss: 3.6375 - sparse_top_k_categorical_accuracy: 0.5048 - val_accuracy: 0.1710 - val_loss: 7.5951 - val_sparse_top_k_categorical_accuracy: 0.3240\n",
      "Epoch 15/30\n",
      "\u001b[1m1493/1493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.3205 - loss: 3.4670 - sparse_top_k_categorical_accuracy: 0.5286\n",
      "Epoch 15: val_loss did not improve from 5.98015\n",
      "\u001b[1m1493/1493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 88ms/step - accuracy: 0.3125 - loss: 3.5315 - sparse_top_k_categorical_accuracy: 0.5199 - val_accuracy: 0.1694 - val_loss: 7.8149 - val_sparse_top_k_categorical_accuracy: 0.3216\n",
      "Epoch 16/30\n",
      "\u001b[1m1493/1493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.3325 - loss: 3.3671 - sparse_top_k_categorical_accuracy: 0.5440\n",
      "Epoch 16: val_loss did not improve from 5.98015\n",
      "\u001b[1m1493/1493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 88ms/step - accuracy: 0.3240 - loss: 3.4351 - sparse_top_k_categorical_accuracy: 0.5339 - val_accuracy: 0.1687 - val_loss: 8.0284 - val_sparse_top_k_categorical_accuracy: 0.3193\n",
      "Epoch 17/30\n",
      "\u001b[1m1493/1493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.3457 - loss: 3.2750 - sparse_top_k_categorical_accuracy: 0.5570\n",
      "Epoch 17: val_loss did not improve from 5.98015\n",
      "\u001b[1m1493/1493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 88ms/step - accuracy: 0.3357 - loss: 3.3422 - sparse_top_k_categorical_accuracy: 0.5475 - val_accuracy: 0.1656 - val_loss: 8.1812 - val_sparse_top_k_categorical_accuracy: 0.3141\n",
      "Epoch 18/30\n",
      "\u001b[1m1493/1493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.3561 - loss: 3.1902 - sparse_top_k_categorical_accuracy: 0.5706\n",
      "Epoch 18: val_loss did not improve from 5.98015\n",
      "\u001b[1m1493/1493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 88ms/step - accuracy: 0.3469 - loss: 3.2570 - sparse_top_k_categorical_accuracy: 0.5606 - val_accuracy: 0.1651 - val_loss: 8.3649 - val_sparse_top_k_categorical_accuracy: 0.3123\n",
      "Epoch 19/30\n",
      "\u001b[1m1493/1493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.3686 - loss: 3.1063 - sparse_top_k_categorical_accuracy: 0.5832\n",
      "Epoch 19: val_loss did not improve from 5.98015\n",
      "\u001b[1m1493/1493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 88ms/step - accuracy: 0.3580 - loss: 3.1778 - sparse_top_k_categorical_accuracy: 0.5726 - val_accuracy: 0.1644 - val_loss: 8.5152 - val_sparse_top_k_categorical_accuracy: 0.3103\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n"
     ]
    }
   ],
   "source": [
    "# Configurar Early Stopping\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',     # Métrica a monitorear\n",
    "    patience=PATIENCE,             # Número de épocas sin mejora antes de parar\n",
    "    restore_best_weights=True,  # Restaurar los mejores pesos\n",
    "    verbose=1               # Mostrar información cuando se pare\n",
    ")\n",
    "\n",
    "print(f\"Entrenando el modelo {'BiLSTM' if USE_BIDIRECTIONAL else 'LSTM'}...\")\n",
    "print(f\"Arquitectura: {EMBEDDING_DIM}D embedding → {'Bi-' if USE_BIDIRECTIONAL else ''}LSTM({LSTM_UNITS}) → Dense({DENSE_UNITS}) → Softmax({vocab_size})\")\n",
    "print(f\"Parámetros de entrenamiento: {EPOCHS} epochs, batch_size={BATCH_SIZE}, lr={LEARNING_RATE}, dropout={DROPOUT_RATE}\")\n",
    "print(f\"Early Stopping habilitado: val_loss con patience={PATIENCE}\")\n",
    "\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "model_name = (\n",
    "    f\"{'BiLSTM' if USE_BIDIRECTIONAL else 'LSTM'}\"\n",
    "    f\"_emb{EMBEDDING_DIM}\"\n",
    "    f\"_take{DATASET_TAKE}\"\n",
    ")\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    f\"models/{model_name}.h5\",\n",
    "    monitor=\"val_loss\",\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "    \n",
    "history = model.fit(\n",
    "    X_train, y_train,  # Usar conjuntos de entrenamiento divididos\n",
    "    epochs=EPOCHS,\n",
    "    verbose=VERBOSE_TRAINING,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_split=VALIDATION_SPLIT,  # Usar datos de entrenamiento para validación\n",
    "    shuffle=True,\n",
    "    callbacks=[early_stopping, checkpoint]  # Agregar Early Stopping y ModelCheckpoint\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Cálculo de la Perplejidad\n",
    "\n",
    "Se immplementan las funciones para calcular la perplejidad.\n",
    "\n",
    "**Fórmula:** `perplexity = exp(-average_log_likelihood)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_perplexity(model, X_test, y_test, batch_size=32):\n",
    "    \"\"\"\n",
    "    Calcula la perplejidad del modelo en el conjunto de prueba de forma segura,\n",
    "    procesando en lotes pequeños para evitar OOM en GPU/CPU.\n",
    "    \"\"\"\n",
    "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "    losses = []\n",
    "\n",
    "    # Procesar el conjunto de prueba en mini-lotes\n",
    "    num_samples = len(X_test)\n",
    "    for start in range(0, num_samples, batch_size):\n",
    "        end = start + batch_size\n",
    "        X_batch = X_test[start:end]\n",
    "        y_batch = y_test[start:end]\n",
    "\n",
    "        preds = model(X_batch, training=False)  # no usar .predict (consume mucha RAM)\n",
    "        batch_loss = loss_fn(y_batch, preds).numpy()\n",
    "        losses.append(batch_loss)\n",
    "\n",
    "    mean_loss = np.mean(losses)\n",
    "    perplexity = float(np.exp(mean_loss))  # PPL = exp(loss promedio)\n",
    "    return perplexity\n",
    "\n",
    "def interpret_perplexity(perplexity_value):\n",
    "    \"\"\"\n",
    "    Interpreta el valor de perplejidad según rangos comunes.\n",
    "    \n",
    "    Args:\n",
    "        perplexity_value (float): Valor de perplejidad calculado\n",
    "        \n",
    "    Returns:\n",
    "        str: Interpretación del valor\n",
    "    \"\"\"\n",
    "    if perplexity_value < 10:\n",
    "        return \"Excelente\"\n",
    "    elif perplexity_value < 50:\n",
    "        return \"Muy bueno\"\n",
    "    elif perplexity_value < 100:\n",
    "        return \"Bueno\"\n",
    "    elif perplexity_value < 200:\n",
    "        return \"Aceptable\"\n",
    "    elif perplexity_value < 500:\n",
    "        return \"Regular\"\n",
    "    else:\n",
    "        return \"Pobre\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Función de guardado de experimentos definida exitosamente!\n"
     ]
    }
   ],
   "source": [
    "def save_experiment_results(history, model, perplexity, vocab_size, X_train, X_test, MAX_LEN):\n",
    "    \"\"\"\n",
    "    Guarda los resultados del experimento en un archivo JSON para llevar historial.\n",
    "    \n",
    "    Args:\n",
    "        history: Historial del entrenamiento\n",
    "        model: Modelo entrenado\n",
    "        perplexity: Valor de perplejidad calculado\n",
    "        vocab_size: Tamaño del vocabulario\n",
    "        X_train, X_test: Conjuntos de datos para obtener tamaños\n",
    "        MAX_LEN: Longitud máxima de secuencia\n",
    "    \"\"\"\n",
    "    # Preparar datos del experimento\n",
    "    experiment_data = {\n",
    "        \"configuration\": {\n",
    "            \"model_type\": \"BiLSTM\" if USE_BIDIRECTIONAL else \"LSTM\",\n",
    "            \"embedding_dim\": EMBEDDING_DIM,\n",
    "            \"lstm_units\": LSTM_UNITS,\n",
    "            \"dense_units\": DENSE_UNITS,\n",
    "            \"epochs\": EPOCHS,\n",
    "            \"batch_size\": BATCH_SIZE,\n",
    "            \"learning_rate\": LEARNING_RATE,\n",
    "            \"dataset_take\": DATASET_TAKE,\n",
    "            \"max_len\": MAX_LEN,\n",
    "            \"padding_type\": PADDING_TYPE,\n",
    "            \"dropout_rate\": DROPOUT_RATE,\n",
    "            \"patience\": PATIENCE,\n",
    "            \"min_words_per_sentence\": MIN_WORDS_PER_SENTENCE,\n",
    "            \"gpu_used\": len(tf.config.list_physical_devices('GPU')) > 0\n",
    "        },\n",
    "        \"dataset_info\": {\n",
    "            \"vocab_size\": int(vocab_size),\n",
    "            \"train_samples\": int(len(X_train)),\n",
    "            \"test_samples\": int(len(X_test)),\n",
    "            \"dataset_name\": DATASET_NAME\n",
    "        },\n",
    "        \"training_results\": {\n",
    "            \"final_train_loss\": float(history.history['loss'][-1]),\n",
    "            \"final_train_accuracy\": float(history.history['accuracy'][-1]),\n",
    "            \"final_val_loss\": float(history.history.get('val_loss', [-1])[-1]) if 'val_loss' in history.history else None,\n",
    "            \"final_val_accuracy\": float(history.history.get('val_accuracy', [-1])[-1]) if 'val_accuracy' in history.history else None,\n",
    "            \"epochs_trained\": len(history.history['loss']),\n",
    "            \"model_parameters\": int(model.count_params())\n",
    "        },\n",
    "        \"evaluation_metrics\": {\n",
    "            \"perplexity\": float(perplexity),\n",
    "            \"perplexity_interpretation\": interpret_perplexity(perplexity)\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Nombre del archivo de historial\n",
    "    results_file = \"experiment_history.json\"\n",
    "    \n",
    "    # Cargar historial existente o crear uno nuevo\n",
    "    if os.path.exists(results_file):\n",
    "        try:\n",
    "            with open(results_file, 'r', encoding='utf-8') as f:\n",
    "                history_data = json.load(f)\n",
    "        except:\n",
    "            history_data = {\"experiments\": []}\n",
    "    else:\n",
    "        history_data = {\"experiments\": []}\n",
    "    \n",
    "    # Agregar nuevo experimento\n",
    "    experiment_data[\"experiment_id\"] = len(history_data[\"experiments\"]) + 1\n",
    "    history_data[\"experiments\"].append(experiment_data)\n",
    "    \n",
    "    # Guardar archivo actualizado\n",
    "    with open(results_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(history_data, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    print(f\"Experimento #{experiment_data['experiment_id']} guardado en {results_file}\")\n",
    "    return results_file\n",
    "\n",
    "print(\"Función de guardado de experimentos definida exitosamente!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Evaluación Completa del Modelo\n",
    "\n",
    "Se evalua el rendimiento del modelo incluyendo perplejidad y métricas estándar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== MÉTRICAS DE ENTRENAMIENTO ===\n",
      "Loss final: 3.1778 | Val Loss: 8.5152\n",
      "Accuracy final: 0.3580 | Val Accuracy: 0.1644\n",
      "\n",
      "=== EVALUACIÓN EN CONJUNTO DE PRUEBA ===\n",
      "Test Loss: 5.9926\n",
      "Test Accuracy: 0.1678\n",
      "Test Top-K Accuracy: 0.3327\n",
      "\n",
      "=== CÁLCULO DE PERPLEJIDAD ===\n",
      "Perplejidad en conjunto de prueba: 400.47\n",
      "Interpretación: Regular\n",
      "\n",
      "=== TABLA DE INTERPRETACIÓN DE PERPLEJIDAD ===\n",
      "< 10:     Excelente\n",
      "10-50:    Muy bueno\n",
      "50-100:   Bueno\n",
      "100-200:  Aceptable\n",
      "200-500:  Regular\n",
      "> 500:    Pobre\n",
      "\n",
      "=== GUARDANDO RESULTADOS DEL EXPERIMENTO ===\n",
      "Experimento #6 guardado en experiment_history.json\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model_performance(history, model, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Muestra métricas de rendimiento del modelo durante el entrenamiento y evaluación.\n",
    "    \"\"\"\n",
    "    print(\"\\n=== MÉTRICAS DE ENTRENAMIENTO ===\")\n",
    "    final_loss = history.history['loss'][-1]\n",
    "    final_accuracy = history.history['accuracy'][-1]\n",
    "    \n",
    "    if 'val_loss' in history.history:\n",
    "        final_val_loss = history.history['val_loss'][-1]\n",
    "        final_val_accuracy = history.history['val_accuracy'][-1]\n",
    "        print(f\"Loss final: {final_loss:.4f} | Val Loss: {final_val_loss:.4f}\")\n",
    "        print(f\"Accuracy final: {final_accuracy:.4f} | Val Accuracy: {final_val_accuracy:.4f}\")\n",
    "    else:\n",
    "        print(f\"Loss final: {final_loss:.4f}\")\n",
    "        print(f\"Accuracy final: {final_accuracy:.4f}\")\n",
    "    \n",
    "    # Evaluar en conjunto de prueba\n",
    "    print(\"\\n=== EVALUACIÓN EN CONJUNTO DE PRUEBA ===\")\n",
    "    test_results = model.evaluate(X_test, y_test, verbose=0)\n",
    "    test_loss = test_results[0]\n",
    "    test_accuracy = test_results[1]\n",
    "    print(f\"Test Loss: {test_loss:.4f}\")\n",
    "    print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "    \n",
    "    # Si hay métricas adicionales, mostrarlas también\n",
    "    if len(test_results) > 2:\n",
    "        test_top_k_accuracy = test_results[2]\n",
    "        print(f\"Test Top-K Accuracy: {test_top_k_accuracy:.4f}\")\n",
    "    \n",
    "    # Calcular perplejidad\n",
    "    print(\"\\n=== CÁLCULO DE PERPLEJIDAD ===\")\n",
    "    perplexity = calculate_perplexity(model, X_test, y_test)\n",
    "    interpretation = interpret_perplexity(perplexity)\n",
    "    \n",
    "    print(f\"Perplejidad en conjunto de prueba: {perplexity:.2f}\")\n",
    "    print(f\"Interpretación: {interpretation}\")\n",
    "    \n",
    "    # Tabla de interpretación\n",
    "    print(\"\\n=== TABLA DE INTERPRETACIÓN DE PERPLEJIDAD ===\")\n",
    "    print(\"< 10:     Excelente\")\n",
    "    print(\"10-50:    Muy bueno\") \n",
    "    print(\"50-100:   Bueno\")\n",
    "    print(\"100-200:  Aceptable\")\n",
    "    print(\"200-500:  Regular\")\n",
    "    print(\"> 500:    Pobre\")\n",
    "    \n",
    "    # Guardar resultados del experimento automáticamente\n",
    "    print(\"\\n=== GUARDANDO RESULTADOS DEL EXPERIMENTO ===\")\n",
    "    try:\n",
    "        save_experiment_results(history, model, perplexity, vocab_size, X_train, X_test, MAX_LEN)\n",
    "    except Exception as e:\n",
    "        print(f\"Error al guardar experimento: {e}\")\n",
    "    \n",
    "    return perplexity\n",
    "\n",
    "# Evaluar rendimiento (incluyendo perplejidad)\n",
    "perplexity = evaluate_model_performance(history, model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Predicción de la Próxima Palabra\n",
    "\n",
    "Se implementa la función `predict_next_word` para predecir la siguiente palabra dada una secuencia de entrada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Funciones de predicción definidas exitosamente!\n"
     ]
    }
   ],
   "source": [
    "def predict_next_word(model, tokenizer, sentence, max_length, top_k=1):\n",
    "    \"\"\"\n",
    "    Predice la(s) palabra(s) siguiente(s) dada una oración en español.\n",
    "    \n",
    "    Args:\n",
    "        model: Modelo entrenado\n",
    "        tokenizer: Tokenizador ajustado\n",
    "        sentence (str): Oración de entrada\n",
    "        max_length (int): Longitud máxima de secuencia\n",
    "        top_k (int): Número de predicciones top a retornar\n",
    "    \n",
    "    Returns:\n",
    "        str o list: Palabra predicha (top_k=1) o lista de predicciones (top_k>1)\n",
    "    \"\"\"\n",
    "    # Tokenizar la oración\n",
    "    sequence = tokenizer.texts_to_sequences([sentence])[0]\n",
    "\n",
    "    if len(sequence) == 0:\n",
    "        return \"<no_reconocido>\" if top_k == 1 else [\"<no_reconocido>\"]\n",
    "\n",
    "    sequence_padded = pad_sequences([sequence], maxlen=max_length, \n",
    "                                  padding=PADDING_TYPE, truncating='pre')\n",
    "\n",
    "    # Usar model() en lugar de model.predict()\n",
    "    prediction = model(sequence_padded, training=False)\n",
    "    \n",
    "    if top_k == 1:\n",
    "        predicted_idx = int(np.argmax(prediction[0]))\n",
    "        predicted_word = tokenizer.index_word.get(predicted_idx, \"<desconocido>\")\n",
    "        return predicted_word\n",
    "    else:\n",
    "        # Convertir a numpy para manipulación\n",
    "        prediction_array = prediction[0].numpy()\n",
    "        top_indices = np.argsort(prediction_array)[-top_k:][::-1]\n",
    "        \n",
    "        predictions = []\n",
    "        for idx in top_indices:\n",
    "            word = tokenizer.index_word.get(int(idx), \"<desconocido>\")\n",
    "            prob = float(prediction_array[idx])\n",
    "            predictions.append((word, prob))\n",
    "        return predictions\n",
    "\n",
    "def generate_text(model, tokenizer, seed_text, max_length, num_words_to_generate=10):\n",
    "    \"\"\"\n",
    "    Genera texto continuando desde un texto semilla.\n",
    "    \n",
    "    Args:\n",
    "        model: Modelo entrenado\n",
    "        tokenizer: Tokenizador ajustado\n",
    "        seed_text (str): Texto inicial\n",
    "        max_length (int): Longitud máxima de secuencia\n",
    "        num_words_to_generate (int): Número de palabras a generar\n",
    "    \n",
    "    Returns:\n",
    "        str: Texto generado\n",
    "    \"\"\"\n",
    "    generated_text = seed_text\n",
    "    \n",
    "    for _ in range(num_words_to_generate):\n",
    "        next_word = predict_next_word(model, tokenizer, generated_text, max_length)\n",
    "        if next_word in [\"<no_reconocido>\", \"<desconocido>\"]:\n",
    "            break\n",
    "        generated_text += \" \" + next_word\n",
    "    \n",
    "    return generated_text\n",
    "\n",
    "print(\"Funciones de predicción definidas exitosamente!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Pruebas de Predicción de Siguiente Palabra\n",
    "\n",
    "Se prueba el modelo con casos de prueba en español."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PREDICCIÓN DE SIGUIENTE PALABRA (BiLSTM) ===\n",
      "'el gato se sentó en la' → 'casa'\n",
      "'los estudiantes abrieron sus' → 'ojos'\n",
      "'la maestra escribió en el' → 'mundo'\n",
      "'el niño jugó con un' → 'poco'\n",
      "'el pájaro voló sobre el' → 'digito'\n",
      "'el sol se elevó en el' → 'mundo'\n",
      "'la casa tiene una' → 'gran'\n",
      "'me gusta comer' → 'a'\n",
      "'vamos a la' → 'señora'\n"
     ]
    }
   ],
   "source": [
    "# Casos de prueba para predicción de siguiente palabra\n",
    "test_cases = [\n",
    "    \"el gato se sentó en la\",\n",
    "    \"los estudiantes abrieron sus\",\n",
    "    \"la maestra escribió en el\",\n",
    "    \"el niño jugó con un\",\n",
    "    \"el pájaro voló sobre el\",\n",
    "    \"el sol se elevó en el\",\n",
    "    \"la casa tiene una\",\n",
    "    \"me gusta comer\",\n",
    "    \"vamos a la\"\n",
    "]\n",
    "\n",
    "print(f\"=== PREDICCIÓN DE SIGUIENTE PALABRA ({'BiLSTM' if USE_BIDIRECTIONAL else 'LSTM'}) ===\")\n",
    "for sentence in test_cases:\n",
    "    next_word = predict_next_word(model, tokenizer, sentence, MAX_LEN)\n",
    "    print(f\"'{sentence}' → '{next_word}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Predicciones Top-K\n",
    "\n",
    "Se muestran las K(3) predicciones más probables para algunos casos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TOP-3 PREDICCIONES ===\n",
      "'el gato se sentó en la':\n",
      "  1. 'casa' (probabilidad: 0.0205)\n",
      "  2. 'señora' (probabilidad: 0.0195)\n",
      "  3. 'puerta' (probabilidad: 0.0191)\n",
      "\n",
      "'los estudiantes abrieron sus':\n",
      "  1. 'ojos' (probabilidad: 0.0069)\n",
      "  2. 'dos' (probabilidad: 0.0068)\n",
      "  3. 'manos' (probabilidad: 0.0061)\n",
      "\n",
      "'la maestra escribió en el':\n",
      "  1. 'mundo' (probabilidad: 0.0341)\n",
      "  2. 'centro' (probabilidad: 0.0110)\n",
      "  3. 'tiempo' (probabilidad: 0.0090)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predicciones top-k para algunos casos\n",
    "print(f\"=== TOP-3 PREDICCIONES ===\")\n",
    "for sentence in test_cases[:3]:\n",
    "    top_predictions = predict_next_word(model, tokenizer, sentence, MAX_LEN, top_k=3)\n",
    "    print(f\"'{sentence}':\")\n",
    "    for i, (word, prob) in enumerate(top_predictions, 1):\n",
    "        print(f\"  {i}. '{word}' (probabilidad: {prob:.4f})\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Generación de Texto\n",
    "\n",
    "Se genera texto continuando desde un texto semilla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== GENERACIÓN DE TEXTO ===\n",
      "Semilla: 'el perro'\n",
      "Generado: 'el perro de la ciudad de la ciudad de la'\n",
      "\n",
      "Semilla: 'los estudiantes'\n",
      "Generado: 'los estudiantes de la ciudad de la ciudad de la'\n",
      "\n",
      "Semilla: 'en la casa'\n",
      "Generado: 'en la casa de la ciudad de la ciudad de la'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generación de texto\n",
    "print(f\"=== GENERACIÓN DE TEXTO ===\")\n",
    "seed_texts = [\n",
    "    \"el perro\",\n",
    "    \"los estudiantes\",\n",
    "    \"en la casa\"\n",
    "]\n",
    "\n",
    "for seed in seed_texts:\n",
    "    generated = generate_text(model, tokenizer, seed, MAX_LEN, num_words_to_generate=8)\n",
    "    print(f\"Semilla: '{seed}'\")\n",
    "    print(f\"Generado: '{generated}'\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. Resumen Final del Modelo\n",
    "\n",
    "Se muestra un resumen completo de las características y rendimiento del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== RESUMEN DEL MODELO ===\n",
      "Vocabulario: 63,944 palabras\n",
      "Secuencias de entrenamiento: 955,451\n",
      "Secuencias de prueba: 238,863\n",
      "Longitud máxima de secuencia (MAX_LEN): 50\n",
      "Arquitectura: BiLSTM\n",
      "Parámetros del modelo: 27,904,168\n",
      "Dataset utilizado: jhonparra18/spanish_billion_words_clean (primeras 50,000 muestras)\n",
      "Perplejidad final: 400.47 (Regular)\n",
      "\n",
      "=== COMPONENTES IMPLEMENTADOS ===\n",
      "Carga del Dataset (spanish_billion_words_clean)\n",
      "Tokenización y Creación del Vocabulario\n",
      "Creación del Conjunto de Entrenamiento (X, Y)\n",
      "Padding y Truncado (MAX_LEN ≤ 50)\n",
      "División del Conjunto (Train/Test 80%/20%)\n",
      "Construcción del Modelo LSTM/BiLSTM\n",
      "Entrenamiento con Early Stopping\n",
      "Cálculo de la Perplejidad\n",
      "Predicción de la Próxima Palabra\n",
      "Uso de sparse_categorical_crossentropy\n"
     ]
    }
   ],
   "source": [
    "print(\"=== RESUMEN DEL MODELO ===\")\n",
    "print(f\"Vocabulario: {vocab_size:,} palabras\")\n",
    "print(f\"Secuencias de entrenamiento: {len(X_train):,}\")\n",
    "print(f\"Secuencias de prueba: {len(X_test):,}\")\n",
    "print(f\"Longitud máxima de secuencia (MAX_LEN): {MAX_LEN}\")\n",
    "print(f\"Arquitectura: {'BiLSTM' if USE_BIDIRECTIONAL else 'LSTM'}\")\n",
    "print(f\"Parámetros del modelo: {model.count_params():,}\")\n",
    "print(f\"Dataset utilizado: {DATASET_NAME} (primeras {DATASET_TAKE:,} muestras)\")\n",
    "print(f\"Perplejidad final: {perplexity:.2f} ({interpret_perplexity(perplexity)})\")\n",
    "\n",
    "print(\"\\n=== COMPONENTES IMPLEMENTADOS ===\")\n",
    "components = [\n",
    "    \"Carga del Dataset (spanish_billion_words_clean)\",\n",
    "    \"Tokenización y Creación del Vocabulario\", \n",
    "    \"Creación del Conjunto de Entrenamiento (X, Y)\",\n",
    "    \"Padding y Truncado (MAX_LEN ≤ 50)\",\n",
    "    \"División del Conjunto (Train/Test 80%/20%)\",\n",
    "    \"Construcción del Modelo LSTM/BiLSTM\",\n",
    "    \"Entrenamiento con Early Stopping\",\n",
    "    \"Cálculo de la Perplejidad\",\n",
    "    \"Predicción de la Próxima Palabra\",\n",
    "    \"Uso de sparse_categorical_crossentropy\"\n",
    "]\n",
    "\n",
    "for component in components:\n",
    "    print(component)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Conclusiones\n",
    "\n",
    "Este notebook implementa completamente los requerimientos de la Tarea 1:\n",
    "\n",
    "1. **Dataset**: Se utilizó `spanish_billion_words_clean` de Hugging Face\n",
    "2. **Tokenización**: Se Implementó con vocabulario único y mapeo palabra↔índice\n",
    "3. **Preparación de datos**: Secuencias (X,Y) con padding/truncado (MAX_LEN≤50)\n",
    "4. **División**: 80% entrenamiento / 20% prueba con `train_test_split`\n",
    "5. **Modelo**: Arquitectura LSTM/BiLSTM configurable con embedding\n",
    "6. **Entrenamiento**: Con Early Stopping y `sparse_categorical_crossentropy`\n",
    "7. **Evaluación**: Perplejidad calculada \n",
    "8. **Predicción**: Función `predict_next_word`\n",
    "\n",
    "El modelo puede alternar entre LSTM y BiLSTM simplemente cambiando `USE_BIDIRECTIONAL=True/False` en los parámetros globales.\n",
    "\n",
    "**Parámetros recomendados para experimentación:**\n",
    "- EMBEDDING_DIM: 100-300\n",
    "- LSTM_UNITS: 64-128\n",
    "- DENSE_UNITS: 64-128\n",
    "- LEARNING_RATE: 0.001-0.01\n",
    "- BATCH_SIZE: 8-32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16. Historial de Experimentos\n",
    "\n",
    "Este bloque muestra todos los experimentos realizados, permitiendo comparar diferentes configuraciones y resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HISTORIAL DE EXPERIMENTOS (6 experimentos)\n",
      "================================================================================\n",
      "\n",
      " RESUMEN COMPARATIVO:\n",
      "ID  Modelo  Sentencias Emb  LSTM  Dense  Épocas  Perplejidad  Interpretacion  GPU    \n",
      "-------------------------------------------------------------------------------------\n",
      "1   LSTM    5000       300  128   128    21      519.71       Pobre           Sí     \n",
      "2   LSTM    20000      300  128   128    20      500.86       Pobre           Sí     \n",
      "3   LSTM    50000      300  128   128    19      398.91       Regular         Sí     \n",
      "4   BiLSTM  5000       300  128   128    22      509.87       Pobre           Sí     \n",
      "5   BiLSTM  20000      300  128   128    19      512.21       Pobre           Sí     \n",
      "6   BiLSTM  50000      300  128   128    19      400.47       Regular         Sí     \n",
      "\n",
      " MEJOR EXPERIMENTO (menor perplejidad):\n",
      "   ID #3: LSTM con perplejidad 398.91 (Regular)\n",
      "\n",
      " PEOR EXPERIMENTO (mayor perplejidad):\n",
      "   ID #1: LSTM con perplejidad 519.71 (Pobre)\n",
      "\n",
      " ESTADÍSTICAS GENERALES:\n",
      "   Perplejidad promedio: 473.67\n",
      "   Rango de perplejidad: 398.91 - 519.71\n",
      "   Experimentos LSTM: 3\n",
      "   Experimentos BiLSTM: 3\n",
      "\n",
      " ÚLTIMO EXPERIMENTO (ID #6):\n",
      "   Modelo: BiLSTM\n",
      "   Configuración: Emb=300, LSTM=128, Dense=128\n",
      "   Entrenamiento: 19 épocas, batch_size=512\n",
      "   Resultados: Perplejidad=400.47 (Regular)\n",
      "   Accuracy final: 0.3580\n",
      "   Val Accuracy: 0.1644\n"
     ]
    }
   ],
   "source": [
    "def load_and_display_experiment_history():\n",
    "    \"\"\"\n",
    "    Carga y muestra el historial completo de experimentos con comparaciones.\n",
    "    \"\"\"\n",
    "    results_file = \"experiment_history.json\"\n",
    "    \n",
    "    if not os.path.exists(results_file):\n",
    "        print(\"No hay historial de experimentos disponible.\")\n",
    "        print(\"Ejecuta el notebook completo para generar el primer experimento.\")\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        with open(results_file, 'r', encoding='utf-8') as f:\n",
    "            history_data = json.load(f)\n",
    "        \n",
    "        experiments = history_data.get(\"experiments\", [])\n",
    "        \n",
    "        if not experiments:\n",
    "            print(\"No hay experimentos en el historial.\")\n",
    "            return\n",
    "        \n",
    "        print(f\"HISTORIAL DE EXPERIMENTOS ({len(experiments)} experimentos)\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        # Mostrar resumen de todos los experimentos\n",
    "        print(\"\\n RESUMEN COMPARATIVO:\")\n",
    "        print(f\"{'ID':<3} {'Modelo':<7} {'Sentencias':<10} {'Emb':<4} {'LSTM':<5} {'Dense':<6} {'Épocas':<7} {'Perplejidad':<12} {'Interpretacion':<15} {'GPU':<7}\")\n",
    "        print(\"-\" * 85)\n",
    "        \n",
    "        for exp in experiments:\n",
    "            config = exp['configuration']\n",
    "            metrics = exp['evaluation_metrics']\n",
    "            training = exp['training_results']\n",
    "            \n",
    "            print(f\"{exp['experiment_id']:<3} \"\n",
    "                  f\"{config['model_type']:<7} \"\n",
    "                  f\"{config['dataset_take']:<10} \"\n",
    "                  f\"{config['embedding_dim']:<4} \"\n",
    "                  f\"{config['lstm_units']:<5} \"\n",
    "                  f\"{config['dense_units']:<6} \"\n",
    "                  f\"{training['epochs_trained']:<7} \"\n",
    "                  f\"{metrics['perplexity']:<12.2f} \"\n",
    "                  f\"{metrics['perplexity_interpretation']:<15} \"\n",
    "                  f\"{'Sí' if config['gpu_used'] else 'No':<7}\"  \n",
    "                )\n",
    "        \n",
    "        # Encontrar mejores y peores experimentos\n",
    "        best_exp = min(experiments, key=lambda x: x['evaluation_metrics']['perplexity'])\n",
    "        worst_exp = max(experiments, key=lambda x: x['evaluation_metrics']['perplexity'])\n",
    "        \n",
    "        print(f\"\\n MEJOR EXPERIMENTO (menor perplejidad):\")\n",
    "        print(f\"   ID #{best_exp['experiment_id']}: {best_exp['configuration']['model_type']} \"\n",
    "              f\"con perplejidad {best_exp['evaluation_metrics']['perplexity']:.2f} \"\n",
    "              f\"({best_exp['evaluation_metrics']['perplexity_interpretation']})\")\n",
    "        \n",
    "        print(f\"\\n PEOR EXPERIMENTO (mayor perplejidad):\")\n",
    "        print(f\"   ID #{worst_exp['experiment_id']}: {worst_exp['configuration']['model_type']} \"\n",
    "              f\"con perplejidad {worst_exp['evaluation_metrics']['perplexity']:.2f} \"\n",
    "              f\"({worst_exp['evaluation_metrics']['perplexity_interpretation']})\")\n",
    "        \n",
    "        # Mostrar estadísticas generales\n",
    "        all_perplexities = [exp['evaluation_metrics']['perplexity'] for exp in experiments]\n",
    "        avg_perplexity = sum(all_perplexities) / len(all_perplexities)\n",
    "        \n",
    "        print(f\"\\n ESTADÍSTICAS GENERALES:\")\n",
    "        print(f\"   Perplejidad promedio: {avg_perplexity:.2f}\")\n",
    "        print(f\"   Rango de perplejidad: {min(all_perplexities):.2f} - {max(all_perplexities):.2f}\")\n",
    "        \n",
    "        # Contar modelos por tipo\n",
    "        lstm_count = sum(1 for exp in experiments if exp['configuration']['model_type'] == 'LSTM')\n",
    "        bilstm_count = sum(1 for exp in experiments if exp['configuration']['model_type'] == 'BiLSTM')\n",
    "        \n",
    "        print(f\"   Experimentos LSTM: {lstm_count}\")\n",
    "        print(f\"   Experimentos BiLSTM: {bilstm_count}\")\n",
    "        \n",
    "        # Mostrar detalles del último experimento\n",
    "        if experiments:\n",
    "            last_exp = experiments[-1]\n",
    "            print(f\"\\n ÚLTIMO EXPERIMENTO (ID #{last_exp['experiment_id']}):\")\n",
    "            print(f\"   Modelo: {last_exp['configuration']['model_type']}\")\n",
    "            print(f\"   Configuración: Emb={last_exp['configuration']['embedding_dim']}, \"\n",
    "                  f\"LSTM={last_exp['configuration']['lstm_units']}, \"\n",
    "                  f\"Dense={last_exp['configuration']['dense_units']}\")\n",
    "            print(f\"   Entrenamiento: {last_exp['training_results']['epochs_trained']} épocas, \"\n",
    "                  f\"batch_size={last_exp['configuration']['batch_size']}\")\n",
    "            print(f\"   Resultados: Perplejidad={last_exp['evaluation_metrics']['perplexity']:.2f} \"\n",
    "                  f\"({last_exp['evaluation_metrics']['perplexity_interpretation']})\")\n",
    "            print(f\"   Accuracy final: {last_exp['training_results']['final_train_accuracy']:.4f}\")\n",
    "            if last_exp['training_results']['final_val_accuracy']:\n",
    "                print(f\"   Val Accuracy: {last_exp['training_results']['final_val_accuracy']:.4f}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\" Error al cargar historial: {e}\")\n",
    "\n",
    "def show_experiment_details(experiment_id):\n",
    "    \"\"\"\n",
    "    Muestra detalles completos de un experimento específico.\n",
    "    \n",
    "    Args:\n",
    "        experiment_id (int): ID del experimento a mostrar\n",
    "    \"\"\"\n",
    "    results_file = \"experiment_history.json\"\n",
    "    \n",
    "    if not os.path.exists(results_file):\n",
    "        print(\"No hay historial de experimentos disponible.\")\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        with open(results_file, 'r', encoding='utf-8') as f:\n",
    "            history_data = json.load(f)\n",
    "        \n",
    "        experiments = history_data.get(\"experiments\", [])\n",
    "        experiment = next((exp for exp in experiments if exp['experiment_id'] == experiment_id), None)\n",
    "        \n",
    "        if not experiment:\n",
    "            print(f\"No se encontró experimento con ID #{experiment_id}\")\n",
    "            return\n",
    "        \n",
    "        print(f\"DETALLES DEL EXPERIMENTO #{experiment_id}\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        config = experiment['configuration']\n",
    "        print(f\"\\n CONFIGURACIÓN:\")\n",
    "        print(f\"   Modelo: {config['model_type']}\")\n",
    "        print(f\"   Embedding: {config['embedding_dim']} dimensiones\")\n",
    "        print(f\"   LSTM Units: {config['lstm_units']}\")\n",
    "        print(f\"   Dense Units: {config['dense_units']}\")\n",
    "        print(f\"   Épocas configuradas: {config['epochs']}\")\n",
    "        print(f\"   Batch Size: {config['batch_size']}\")\n",
    "        print(f\"   Learning Rate: {config['learning_rate']}\")\n",
    "        print(f\"   Dataset samples: {config['dataset_take']:,}\")\n",
    "        print(f\"   MAX_LEN: {config['max_len']}\")\n",
    "        \n",
    "        dataset = experiment['dataset_info']\n",
    "        print(f\"\\n DATOS:\")\n",
    "        print(f\"   Vocabulario: {dataset['vocab_size']:,} palabras\")\n",
    "        print(f\"   Entrenamiento: {dataset['train_samples']:,} muestras\")\n",
    "        print(f\"   Prueba: {dataset['test_samples']:,} muestras\")\n",
    "        \n",
    "        training = experiment['training_results']\n",
    "        print(f\"\\n ENTRENAMIENTO:\")\n",
    "        print(f\"   Épocas entrenadas: {training['epochs_trained']}\")\n",
    "        print(f\"   Loss final: {training['final_train_loss']:.4f}\")\n",
    "        print(f\"   Accuracy final: {training['final_train_accuracy']:.4f}\")\n",
    "        if training['final_val_loss']:\n",
    "            print(f\"   Validation Loss: {training['final_val_loss']:.4f}\")\n",
    "            print(f\"   Validation Accuracy: {training['final_val_accuracy']:.4f}\")\n",
    "        print(f\"   Parámetros del modelo: {training['model_parameters']:,}\")\n",
    "        \n",
    "        metrics = experiment['evaluation_metrics']\n",
    "        print(f\"\\n EVALUACIÓN:\")\n",
    "        print(f\"   Perplejidad: {metrics['perplexity']:.2f}\")\n",
    "        print(f\"   Interpretación: {metrics['perplexity_interpretation']}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error al mostrar detalles: {e}\")\n",
    "\n",
    "# Cargar y mostrar historial\n",
    "load_and_display_experiment_history()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310ia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
