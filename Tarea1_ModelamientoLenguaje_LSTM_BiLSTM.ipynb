{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taller 1: Aplicación de RNNs al Modelamiento de Lenguaje en Español (LSTM/BiLSTM)\n",
    "\n",
    "**Curso:** PLN\n",
    "**Objetivo:** Experimentar con modelos de Redes Neuronales Recurrentes (RNNs), específicamente LSTM y BiLSTM, para el modelado del lenguaje en español. \n",
    "**Autor:** Herney Eduardo Quintero Trochez  \n",
    "**Fecha:** 2025  \n",
    "**Universidad:** Universidad Del Valle  \n",
    "**Curso:** Procesamiento de Lenguaje Natural (PLN) - Taller 1\n",
    "## Componentes implementados:\n",
    "1. Carga del Dataset (`spanish_billion_words_clean`)\n",
    "2. Tokenización y Creación del Vocabulario\n",
    "3. Creación del Conjunto de Entrenamiento (X, Y)\n",
    "4. Padding y Truncado (MAX_LEN ≤ 50)\n",
    "5. División del Conjunto (Train/Test 80%/20%)\n",
    "6. Construcción del Modelo LSTM/BiLSTM\n",
    "7. Entrenamiento con Early Stopping\n",
    "8. Cálculo de la Perplejidad\n",
    "9. Predicción de la Próxima Palabra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Configuración de Parámetros Globales\n",
    "\n",
    "Esta sección permite modificar fácilmente todos los parámetros del modelo para experimentar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset configuration\n",
    "DATASET_NAME = \"jhonparra18/spanish_billion_words_clean\"\n",
    "DATASET_SPLIT = \"train\"\n",
    "DATASET_STREAMING = True\n",
    "DATASET_TAKE = 5000  # Número de ejemplos a tomar del dataset\n",
    "MIN_WORDS_PER_SENTENCE = 4  # Filtro: oraciones con al menos N palabras\n",
    "OOV_TOKEN = \"<OOV>\"  # Token para palabras fuera del vocabulario\n",
    "\n",
    "# Model architecture parameters\n",
    "EMBEDDING_DIM = 50  # Dimensión del embedding de palabras\n",
    "LSTM_UNITS = 64  # Número de unidades en las capas LSTM\n",
    "DENSE_UNITS = 64  # Número de unidades en la capa densa intermedia\n",
    "USE_BIDIRECTIONAL = True  # Usar BiLSTM en lugar de LSTM unidireccional\n",
    "\n",
    "# Training parameters\n",
    "EPOCHS = 30  # Número de épocas de entrenamiento\n",
    "BATCH_SIZE = 8  # Tamaño del batch\n",
    "VALIDATION_SPLIT = 0.2  # Porcentaje de datos para validación\n",
    "LEARNING_RATE = 0.001  # Tasa de aprendizaje\n",
    "\n",
    "# Sequence processing\n",
    "PADDING_TYPE = 'pre'  # Tipo de padding: 'pre' o 'post'\n",
    "\n",
    "# Output parameters\n",
    "VERBOSE_TRAINING = 1  # Nivel de verbosidad durante entrenamiento\n",
    "VERBOSE_PREDICTION = 0  # Nivel de verbosidad durante predicción\n",
    "\n",
    "print(f\"Configuración cargada:\")\n",
    "print(f\"- Modelo: {'BiLSTM' if USE_BIDIRECTIONAL else 'LSTM'}\")\n",
    "print(f\"- Dataset: {DATASET_TAKE:,} muestras de {DATASET_NAME}\")\n",
    "print(f\"- Arquitectura: {EMBEDDING_DIM}D embedding → LSTM({LSTM_UNITS}) → Dense({DENSE_UNITS})\")\n",
    "print(f\"- Entrenamiento: {EPOCHS} epochs, batch_size={BATCH_SIZE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importación de Librerías\n",
    "\n",
    "Se importan todas las librerías necesarias para el proyecto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import load_dataset\n",
    "import math\n",
    "\n",
    "print(\"Librerías importadas exitosamente!\")\n",
    "print(f\"TensorFlow version: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Carga del Dataset\n",
    "\n",
    "Se carga el dataset `spanish_billion_words_clean` de Hugging Face y se filtran oraciones muy cortas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Cargando dataset...\")\n",
    "dataset = load_dataset(DATASET_NAME, split=DATASET_SPLIT, streaming=DATASET_STREAMING).take(DATASET_TAKE)\n",
    "sentences = [example['text'] for example in dataset if len(example['text'].split()) >= MIN_WORDS_PER_SENTENCE]\n",
    "\n",
    "print(f\"Total de oraciones cargadas: {len(sentences)}\")\n",
    "print(\"\\nEjemplos de oraciones:\")\n",
    "for i, sentence in enumerate(sentences[:5]):\n",
    "    print(f\"{i+1}. {sentence}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Tokenización y Creación del Vocabulario\n",
    "\n",
    "Se Tokenizan las oraciones y se crea el vocabulario con mapeo palabra→índice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(oov_token=OOV_TOKEN)  # Token para palabras desconocidas\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "\n",
    "# Convertir frases a secuencias numéricas\n",
    "sequences = tokenizer.texts_to_sequences(sentences)\n",
    "\n",
    "# Tamaño del vocabulario\n",
    "vocab_size = len(tokenizer.word_index) + 1  # +1 por el padding (índice 0)\n",
    "print(f\"Vocabulario: {vocab_size} palabras\")\n",
    "\n",
    "print(\"\\nPrimeras 10 palabras del vocabulario:\")\n",
    "for i, (word, idx) in enumerate(list(tokenizer.word_index.items())[:10]):\n",
    "    print(f\"{word} → {idx}\")\n",
    "\n",
    "print(f\"\\nEjemplo de tokenización:\")\n",
    "example_sentence = sentences[0]\n",
    "example_sequence = sequences[0]\n",
    "print(f\"Oración: {example_sentence}\")\n",
    "print(f\"Secuencia: {example_sequence}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Creación del Conjunto de Entrenamiento (X, Y)\n",
    "\n",
    "Para cada secuencia `[w1, w2, ..., wn]`, se crean pares:\n",
    "- `(w1) → w2`\n",
    "- `(w1, w2) → w3`\n",
    "- `...`\n",
    "- `(w1, ..., wn-1) → wn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []  # Secuencias de entrada: [palabra1], [palabra1, palabra2], ...\n",
    "y = []  # Palabra siguiente (objetivo)\n",
    "\n",
    "for seq in sequences:\n",
    "    for i in range(len(seq) - 1):\n",
    "        X.append(seq[:i+1])    # Desde el inicio hasta la palabra actual\n",
    "        y.append(seq[i+1])     # La siguiente palabra\n",
    "\n",
    "print(f\"Total de secuencias de entrenamiento generadas: {len(X)}\")\n",
    "print(\"\\nEjemplos de secuencias X → y:\")\n",
    "for i in range(5):\n",
    "    # Convertir índices a palabras para mostrar\n",
    "    x_words = [tokenizer.index_word.get(idx, '<UNK>') for idx in X[i]]\n",
    "    y_word = tokenizer.index_word.get(y[i], '<UNK>')\n",
    "    print(f\"{x_words} → {y_word}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Padding y Truncado (MAX_LEN ≤ 50)\n",
    "\n",
    "Se Aplica padding a las secuencias y se trunca si la longitud máxima excede 50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Longitud máxima de las secuencias (con restricción MAX_LEN <= 50)\n",
    "raw_max_length = max([len(seq) for seq in X])\n",
    "MAX_LEN = min(50, raw_max_length)  # Aplicar restricción de máximo 50\n",
    "print(f\"Longitud máxima encontrada: {raw_max_length}\")\n",
    "print(f\"MAX_LEN aplicado (truncado a 50): {MAX_LEN}\")\n",
    "\n",
    "# Aplicar padding y truncado a las secuencias de entrada\n",
    "X_padded = pad_sequences(X, maxlen=MAX_LEN, padding=PADDING_TYPE, truncating='pre')\n",
    "y = np.array(y)  # Etiquetas: ya es un array 1D\n",
    "\n",
    "print(f\"\\nForma de X_padded: {X_padded.shape}\")  # (número de muestras, MAX_LEN)\n",
    "print(f\"Forma de y: {y.shape}\")\n",
    "print(\"\\nEjemplo de X_padded (primeras 3 secuencias):\")\n",
    "print(X_padded[:3])\n",
    "print(\"\\nEjemplo de y (primeras 10 etiquetas):\")\n",
    "print(y[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. División del Conjunto (Train/Test: 80%/20%)\n",
    "\n",
    "Se dividen los datos en conjuntos de entrenamiento y prueba usando `train_test_split`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_padded, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "print(f\"División del conjunto:\")\n",
    "print(f\"X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
    "print(f\"X_test: {X_test.shape}, y_test: {y_test.shape}\")\n",
    "print(f\"\\nPorcentajes:\")\n",
    "print(f\"Entrenamiento: {len(X_train)/(len(X_train)+len(X_test))*100:.1f}%\")\n",
    "print(f\"Prueba: {len(X_test)/(len(X_train)+len(X_test))*100:.1f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Construcción del Modelo LSTM/BiLSTM\n",
    "\n",
    "Se crea el modelo con arquitectura configurable (LSTM o BiLSTM) y se compila con `sparse_categorical_crossentropy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(vocab_size, max_length):\n",
    "    \"\"\"\n",
    "    Crea un modelo de lenguaje usando BiLSTM o LSTM según configuración.\n",
    "    \n",
    "    Args:\n",
    "        vocab_size (int): Tamaño del vocabulario\n",
    "        max_length (int): Longitud máxima de las secuencias\n",
    "    \n",
    "    Returns:\n",
    "        tensorflow.keras.Model: Modelo compilado\n",
    "    \"\"\"\n",
    "    model = Sequential([\n",
    "        Embedding(vocab_size, EMBEDDING_DIM, input_length=max_length, name='embedding'),\n",
    "        # Usar BiLSTM si está habilitado, sino LSTM unidireccional\n",
    "        Bidirectional(LSTM(LSTM_UNITS, name='lstm'), name='bidirectional_lstm') if USE_BIDIRECTIONAL \n",
    "        else LSTM(LSTM_UNITS, name='lstm'),\n",
    "        Dense(DENSE_UNITS, activation='relu', name='dense_hidden'),\n",
    "        Dense(vocab_size, activation='softmax', name='output')  # Probabilidades para cada palabra\n",
    "    ])\n",
    "    \n",
    "    # Configurar optimizador con tasa de aprendizaje personalizada\n",
    "    optimizer = Adam(learning_rate=LEARNING_RATE)\n",
    "    \n",
    "    # Usar sparse_categorical_crossentropy (NO necesita one-hot encoding)\n",
    "    model.compile(\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        optimizer=optimizer,\n",
    "        metrics=['accuracy', 'sparse_top_k_categorical_accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = create_model(vocab_size, MAX_LEN)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Entrenamiento del Modelo con Early Stopping\n",
    "\n",
    "Se entrena el modelo con Early Stopping para prevenir overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar Early Stopping\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',     # Métrica a monitorear\n",
    "    patience=5,             # Número de épocas sin mejora antes de parar\n",
    "    restore_best_weights=True,  # Restaurar los mejores pesos\n",
    "    verbose=1               # Mostrar información cuando se pare\n",
    ")\n",
    "\n",
    "print(f\"Entrenando el modelo {'BiLSTM' if USE_BIDIRECTIONAL else 'LSTM'}...\")\n",
    "print(f\"Arquitectura: {EMBEDDING_DIM}D embedding → {'Bi-' if USE_BIDIRECTIONAL else ''}LSTM({LSTM_UNITS}) → Dense({DENSE_UNITS}) → Softmax({vocab_size})\")\n",
    "print(f\"Parámetros de entrenamiento: {EPOCHS} epochs, batch_size={BATCH_SIZE}, lr={LEARNING_RATE}\")\n",
    "print(\"Early Stopping habilitado: val_loss con patience=5\")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,  # Usar conjuntos de entrenamiento divididos\n",
    "    epochs=EPOCHS,\n",
    "    verbose=VERBOSE_TRAINING,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_split=VALIDATION_SPLIT,  # Usar datos de entrenamiento para validación\n",
    "    shuffle=True,\n",
    "    callbacks=[early_stopping]  # Agregar Early Stopping\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Cálculo de la Perplejidad\n",
    "\n",
    "Se immplementan las funciones para calcular la perplejidad.\n",
    "\n",
    "**Fórmula:** `perplexity = exp(-average_log_likelihood)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_perplexity(model, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Calcula la perplejidad del modelo en el conjunto de prueba.\n",
    "    \n",
    "    La perplejidad es una medida de qué tan bien un modelo de probabilidad \n",
    "    predice una muestra. Valores más bajos indican mejor rendimiento.\n",
    "    \n",
    "    Fórmula: perplexity = exp(average_negative_log_likelihood)\n",
    "    \n",
    "    Args:\n",
    "        model: Modelo entrenado\n",
    "        X_test: Conjunto de prueba de entrada\n",
    "        y_test: Conjunto de prueba de salida (etiquetas verdaderas)\n",
    "    \n",
    "    Returns:\n",
    "        float: Valor de perplejidad\n",
    "    \"\"\"\n",
    "    # Obtener probabilidades predichas para el conjunto de prueba\n",
    "    predictions = model.predict(X_test, verbose=0)\n",
    "    \n",
    "    # Calcular log-likelihood promedio\n",
    "    log_likelihoods = []\n",
    "    for i in range(len(y_test)):\n",
    "        true_word_idx = y_test[i]\n",
    "        predicted_prob = predictions[i][true_word_idx]\n",
    "        # Evitar log(0) agregando un pequeño epsilon\n",
    "        predicted_prob = max(predicted_prob, 1e-10)\n",
    "        log_likelihoods.append(np.log(predicted_prob))\n",
    "    \n",
    "    # Calcular perplejidad\n",
    "    average_log_likelihood = np.mean(log_likelihoods)\n",
    "    perplexity = np.exp(-average_log_likelihood)\n",
    "    \n",
    "    return perplexity\n",
    "\n",
    "def interpret_perplexity(perplexity_value):\n",
    "    \"\"\"\n",
    "    Interpreta el valor de perplejidad según rangos comunes.\n",
    "    \n",
    "    Args:\n",
    "        perplexity_value (float): Valor de perplejidad calculado\n",
    "        \n",
    "    Returns:\n",
    "        str: Interpretación del valor\n",
    "    \"\"\"\n",
    "    if perplexity_value < 10:\n",
    "        return \"Excelente\"\n",
    "    elif perplexity_value < 50:\n",
    "        return \"Muy bueno\"\n",
    "    elif perplexity_value < 100:\n",
    "        return \"Bueno\"\n",
    "    elif perplexity_value < 200:\n",
    "        return \"Aceptable\"\n",
    "    elif perplexity_value < 500:\n",
    "        return \"Regular\"\n",
    "    else:\n",
    "        return \"Pobre\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Evaluación Completa del Modelo\n",
    "\n",
    "Se evalua el rendimiento del modelo incluyendo perplejidad y métricas estándar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_performance(history, model, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Muestra métricas de rendimiento del modelo durante el entrenamiento y evaluación.\n",
    "    \"\"\"\n",
    "    print(\"\\n=== MÉTRICAS DE ENTRENAMIENTO ===\")\n",
    "    final_loss = history.history['loss'][-1]\n",
    "    final_accuracy = history.history['accuracy'][-1]\n",
    "    \n",
    "    if 'val_loss' in history.history:\n",
    "        final_val_loss = history.history['val_loss'][-1]\n",
    "        final_val_accuracy = history.history['val_accuracy'][-1]\n",
    "        print(f\"Loss final: {final_loss:.4f} | Val Loss: {final_val_loss:.4f}\")\n",
    "        print(f\"Accuracy final: {final_accuracy:.4f} | Val Accuracy: {final_val_accuracy:.4f}\")\n",
    "    else:\n",
    "        print(f\"Loss final: {final_loss:.4f}\")\n",
    "        print(f\"Accuracy final: {final_accuracy:.4f}\")\n",
    "    \n",
    "    # Evaluar en conjunto de prueba\n",
    "    print(\"\\n=== EVALUACIÓN EN CONJUNTO DE PRUEBA ===\")\n",
    "    test_results = model.evaluate(X_test, y_test, verbose=0)\n",
    "    test_loss = test_results[0]\n",
    "    test_accuracy = test_results[1]\n",
    "    print(f\"Test Loss: {test_loss:.4f}\")\n",
    "    print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "    \n",
    "    # Si hay métricas adicionales, mostrarlas también\n",
    "    if len(test_results) > 2:\n",
    "        test_top_k_accuracy = test_results[2]\n",
    "        print(f\"Test Top-K Accuracy: {test_top_k_accuracy:.4f}\")\n",
    "    \n",
    "    # Calcular perplejidad\n",
    "    print(\"\\n=== CÁLCULO DE PERPLEJIDAD ===\")\n",
    "    perplexity = calculate_perplexity(model, X_test, y_test)\n",
    "    interpretation = interpret_perplexity(perplexity)\n",
    "    \n",
    "    print(f\"Perplejidad en conjunto de prueba: {perplexity:.2f}\")\n",
    "    print(f\"Interpretación: {interpretation}\")\n",
    "    \n",
    "    # Tabla de interpretación\n",
    "    print(\"\\n=== TABLA DE INTERPRETACIÓN DE PERPLEJIDAD ===\")\n",
    "    print(\"< 10:     Excelente\")\n",
    "    print(\"10-50:    Muy bueno\") \n",
    "    print(\"50-100:   Bueno\")\n",
    "    print(\"100-200:  Aceptable\")\n",
    "    print(\"200-500:  Regular\")\n",
    "    print(\"> 500:    Pobre\")\n",
    "    \n",
    "    return perplexity\n",
    "\n",
    "# Evaluar rendimiento (incluyendo perplejidad)\n",
    "perplexity = evaluate_model_performance(history, model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Predicción de la Próxima Palabra\n",
    "\n",
    "Se implementa la función `predict_next_word` para predecir la siguiente palabra dada una secuencia de entrada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next_word(model, tokenizer, sentence, max_length, top_k=1):\n",
    "    \"\"\"\n",
    "    Predice la(s) palabra(s) siguiente(s) dada una oración en español.\n",
    "    \n",
    "    Args:\n",
    "        model: Modelo entrenado\n",
    "        tokenizer: Tokenizador ajustado\n",
    "        sentence (str): Oración de entrada\n",
    "        max_length (int): Longitud máxima de secuencia\n",
    "        top_k (int): Número de predicciones top a retornar\n",
    "    \n",
    "    Returns:\n",
    "        str o list: Palabra predicha (top_k=1) o lista de predicciones (top_k>1)\n",
    "    \"\"\"\n",
    "    # Tokenizar la oración\n",
    "    sequence = tokenizer.texts_to_sequences([sentence])[0]\n",
    "\n",
    "    if len(sequence) == 0:\n",
    "        return \"<no_reconocido>\" if top_k == 1 else [\"<no_reconocido>\"]\n",
    "\n",
    "    # Aplicar padding usando el mismo tipo configurado\n",
    "    sequence_padded = pad_sequences([sequence], maxlen=max_length, padding=PADDING_TYPE, truncating='pre')\n",
    "\n",
    "    # Predecir probabilidades\n",
    "    prediction = model.predict(sequence_padded, verbose=VERBOSE_PREDICTION)\n",
    "    \n",
    "    if top_k == 1:\n",
    "        # Retornar solo la predicción más probable\n",
    "        predicted_idx = np.argmax(prediction[0])\n",
    "        predicted_word = tokenizer.index_word.get(predicted_idx, \"<desconocido>\")\n",
    "        return predicted_word\n",
    "    else:\n",
    "        # Retornar las top_k predicciones más probables\n",
    "        top_indices = np.argsort(prediction[0])[-top_k:][::-1]\n",
    "        predictions = []\n",
    "        for idx in top_indices:\n",
    "            word = tokenizer.index_word.get(idx, \"<desconocido>\")\n",
    "            prob = prediction[0][idx]\n",
    "            predictions.append((word, prob))\n",
    "        return predictions\n",
    "\n",
    "def generate_text(model, tokenizer, seed_text, max_length, num_words_to_generate=10):\n",
    "    \"\"\"\n",
    "    Genera texto continuando desde un texto semilla.\n",
    "    \n",
    "    Args:\n",
    "        model: Modelo entrenado\n",
    "        tokenizer: Tokenizador ajustado\n",
    "        seed_text (str): Texto inicial\n",
    "        max_length (int): Longitud máxima de secuencia\n",
    "        num_words_to_generate (int): Número de palabras a generar\n",
    "    \n",
    "    Returns:\n",
    "        str: Texto generado\n",
    "    \"\"\"\n",
    "    generated_text = seed_text\n",
    "    \n",
    "    for _ in range(num_words_to_generate):\n",
    "        next_word = predict_next_word(model, tokenizer, generated_text, max_length)\n",
    "        if next_word in [\"<no_reconocido>\", \"<desconocido>\"]:\n",
    "            break\n",
    "        generated_text += \" \" + next_word\n",
    "    \n",
    "    return generated_text\n",
    "\n",
    "print(\"Funciones de predicción definidas exitosamente!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Pruebas de Predicción de Siguiente Palabra\n",
    "\n",
    "Se prueba el modelo con casos de prueba en español."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Casos de prueba para predicción de siguiente palabra\n",
    "test_cases = [\n",
    "    \"el gato se sentó en la\",\n",
    "    \"los estudiantes abrieron sus\",\n",
    "    \"la maestra escribió en el\",\n",
    "    \"el niño jugó con un\",\n",
    "    \"el pájaro voló sobre el\",\n",
    "    \"el sol se elevó en el\",\n",
    "    \"la casa tiene una\",\n",
    "    \"me gusta comer\",\n",
    "    \"vamos a la\"\n",
    "]\n",
    "\n",
    "print(f\"=== PREDICCIÓN DE SIGUIENTE PALABRA ({'BiLSTM' if USE_BIDIRECTIONAL else 'LSTM'}) ===\")\n",
    "for sentence in test_cases:\n",
    "    next_word = predict_next_word(model, tokenizer, sentence, MAX_LEN)\n",
    "    print(f\"'{sentence}' → '{next_word}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Predicciones Top-K\n",
    "\n",
    "Se muestran las K(3) predicciones más probables para algunos casos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicciones top-k para algunos casos\n",
    "print(f\"=== TOP-3 PREDICCIONES ===\")\n",
    "for sentence in test_cases[:3]:\n",
    "    top_predictions = predict_next_word(model, tokenizer, sentence, MAX_LEN, top_k=3)\n",
    "    print(f\"'{sentence}':\")\n",
    "    for i, (word, prob) in enumerate(top_predictions, 1):\n",
    "        print(f\"  {i}. '{word}' (probabilidad: {prob:.4f})\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Generación de Texto\n",
    "\n",
    "Se genera texto continuando desde un texto semilla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generación de texto\n",
    "print(f\"=== GENERACIÓN DE TEXTO ===\")\n",
    "seed_texts = [\n",
    "    \"el perro\",\n",
    "    \"los estudiantes\",\n",
    "    \"en la casa\"\n",
    "]\n",
    "\n",
    "for seed in seed_texts:\n",
    "    generated = generate_text(model, tokenizer, seed, MAX_LEN, num_words_to_generate=8)\n",
    "    print(f\"Semilla: '{seed}'\")\n",
    "    print(f\"Generado: '{generated}'\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. Resumen Final del Modelo\n",
    "\n",
    "Se muestra un resumen completo de las características y rendimiento del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== RESUMEN DEL MODELO ===\")\n",
    "print(f\"Vocabulario: {vocab_size:,} palabras\")\n",
    "print(f\"Secuencias de entrenamiento: {len(X_train):,}\")\n",
    "print(f\"Secuencias de prueba: {len(X_test):,}\")\n",
    "print(f\"Longitud máxima de secuencia (MAX_LEN): {MAX_LEN}\")\n",
    "print(f\"Arquitectura: {'BiLSTM' if USE_BIDIRECTIONAL else 'LSTM'}\")\n",
    "print(f\"Parámetros del modelo: {model.count_params():,}\")\n",
    "print(f\"Dataset utilizado: {DATASET_NAME} (primeras {DATASET_TAKE:,} muestras)\")\n",
    "print(f\"Perplejidad final: {perplexity:.2f} ({interpret_perplexity(perplexity)})\")\n",
    "\n",
    "print(\"\\n=== COMPONENTES IMPLEMENTADOS ===\")\n",
    "components = [\n",
    "    \"Carga del Dataset (spanish_billion_words_clean)\",\n",
    "    \"Tokenización y Creación del Vocabulario\", \n",
    "    \"Creación del Conjunto de Entrenamiento (X, Y)\",\n",
    "    \"Padding y Truncado (MAX_LEN ≤ 50)\",\n",
    "    \"División del Conjunto (Train/Test 80%/20%)\",\n",
    "    \"Construcción del Modelo LSTM/BiLSTM\",\n",
    "    \"Entrenamiento con Early Stopping\",\n",
    "    \"Cálculo de la Perplejidad\",\n",
    "    \"Predicción de la Próxima Palabra\",\n",
    "    \"Uso de sparse_categorical_crossentropy\"\n",
    "]\n",
    "\n",
    "for component in components:\n",
    "    print(component)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Conclusiones\n",
    "\n",
    "Este notebook implementa completamente los requerimientos de la Tarea 1:\n",
    "\n",
    "1. **Dataset**: Se utilizó `spanish_billion_words_clean` de Hugging Face\n",
    "2. **Tokenización**: Se Implementó con vocabulario único y mapeo palabra↔índice\n",
    "3. **Preparación de datos**: Secuencias (X,Y) con padding/truncado (MAX_LEN≤50)\n",
    "4. **División**: 80% entrenamiento / 20% prueba con `train_test_split`\n",
    "5. **Modelo**: Arquitectura LSTM/BiLSTM configurable con embedding\n",
    "6. **Entrenamiento**: Con Early Stopping y `sparse_categorical_crossentropy`\n",
    "7. **Evaluación**: Perplejidad calculada \n",
    "8. **Predicción**: Función `predict_next_word`\n",
    "\n",
    "El modelo puede alternar entre LSTM y BiLSTM simplemente cambiando `USE_BIDIRECTIONAL=True/False` en los parámetros globales.\n",
    "\n",
    "**Parámetros recomendados para experimentación:**\n",
    "- EMBEDDING_DIM: 100-300\n",
    "- LSTM_UNITS: 64-128\n",
    "- DENSE_UNITS: 64-128\n",
    "- LEARNING_RATE: 0.001-0.01\n",
    "- BATCH_SIZE: 8-32"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39ia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
