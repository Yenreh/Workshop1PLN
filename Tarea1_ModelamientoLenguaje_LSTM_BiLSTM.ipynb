{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taller 1: Aplicación de RNNs al Modelamiento de Lenguaje en Español (LSTM/BiLSTM)\n",
    "\n",
    "**Curso:** PLN\n",
    "**Objetivo:** Experimentar con modelos de Redes Neuronales Recurrentes (RNNs), específicamente LSTM y BiLSTM, para el modelado del lenguaje en español. \n",
    "**Autor:** Herney Eduardo Quintero Trochez  \n",
    "**Fecha:** 2025  \n",
    "**Universidad:** Universidad Del Valle  \n",
    "**Curso:** Procesamiento de Lenguaje Natural (PLN) - Taller 1\n",
    "## Componentes implementados:\n",
    "1. Carga del Dataset (`spanish_billion_words_clean`)\n",
    "2. Tokenización y Creación del Vocabulario\n",
    "3. Creación del Conjunto de Entrenamiento (X, Y)\n",
    "4. Padding y Truncado (MAX_LEN ≤ 50)\n",
    "5. División del Conjunto (Train/Test 80%/20%)\n",
    "6. Construcción del Modelo LSTM/BiLSTM\n",
    "7. Entrenamiento con Early Stopping\n",
    "8. Cálculo de la Perplejidad\n",
    "9. Predicción de la Próxima Palabra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Configuración de Parámetros Globales\n",
    "\n",
    "Esta sección permite modificar fácilmente todos los parámetros del modelo para experimentar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuración cargada:\n",
      "- Modelo: LSTM\n",
      "- Dataset: 20,000 muestras de jhonparra18/spanish_billion_words_clean\n",
      "- Arquitectura: 300D embedding → LSTM(128) → Dense(128)\n",
      "- Entrenamiento: 30 epochs, batch_size=32\n"
     ]
    }
   ],
   "source": [
    "# Dataset configuration\n",
    "DATASET_NAME = \"jhonparra18/spanish_billion_words_clean\"\n",
    "DATASET_SPLIT = \"train\"\n",
    "DATASET_STREAMING = True\n",
    "DATASET_TAKE = 20000  # Número de ejemplos a tomar del dataset\n",
    "MIN_WORDS_PER_SENTENCE = 4  # Filtro: oraciones con al menos N palabras\n",
    "OOV_TOKEN = \"<OOV>\"  # Token para palabras fuera del vocabulario\n",
    "\n",
    "# Model architecture parameters\n",
    "EMBEDDING_DIM = 300  # Dimensión del embedding de palabras\n",
    "LSTM_UNITS = 128 # Número de unidades en las capas LSTM\n",
    "DENSE_UNITS = 128  # Número de unidades en la capa densa intermedia\n",
    "USE_BIDIRECTIONAL = False  # Usar BiLSTM en lugar de LSTM unidireccional\n",
    "\n",
    "# Training parameters\n",
    "EPOCHS = 30  # Número de épocas de entrenamiento\n",
    "BATCH_SIZE = 32  # Tamaño del batch\n",
    "VALIDATION_SPLIT = 0.2  # Porcentaje de datos para validación\n",
    "LEARNING_RATE = 0.001  # Tasa de aprendizaje\n",
    "\n",
    "# Sequence processing\n",
    "PADDING_TYPE = 'pre'  # Tipo de padding: 'pre' o 'post'\n",
    "\n",
    "# Output parameters\n",
    "VERBOSE_TRAINING = 1  # Nivel de verbose durante entrenamiento\n",
    "VERBOSE_PREDICTION = 0  # Nivel de verbose durante predicción\n",
    "\n",
    "print(f\"Configuración cargada:\")\n",
    "print(f\"- Modelo: {'BiLSTM' if USE_BIDIRECTIONAL else 'LSTM'}\")\n",
    "print(f\"- Dataset: {DATASET_TAKE:,} muestras de {DATASET_NAME}\")\n",
    "print(f\"- Arquitectura: {EMBEDDING_DIM}D embedding → LSTM({LSTM_UNITS}) → Dense({DENSE_UNITS})\")\n",
    "print(f\"- Entrenamiento: {EPOCHS} epochs, batch_size={BATCH_SIZE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importación de Librerías\n",
    "\n",
    "Se importan todas las librerías necesarias para el proyecto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-25 19:31:59.794475: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-25 19:31:59.836882: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-25 19:32:00.785344: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "/home/yenreh/anaconda3/envs/py310ia/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Librerías importadas exitosamente!\n",
      "TensorFlow version: 2.20.0\n",
      "GPU detectada: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import load_dataset\n",
    "import math\n",
    "import json\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "print(\"Librerías importadas exitosamente!\")\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    print(f\"GPU detectada: {gpus}\")\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "else:\n",
    "    print(\"No se detectó GPU, usando CPU.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Carga del Dataset\n",
    "\n",
    "Se carga el dataset `spanish_billion_words_clean` de Hugging Face y se filtran oraciones muy cortas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando dataset...\n",
      "Total de oraciones cargadas: 20000\n",
      "\n",
      "Ejemplos de oraciones:\n",
      "1. source wikisource librodot com sentido y sensibilidad jane austen capitulo i\n",
      "2. la familia dashwood llevaba largo tiempo afincada en sussex\n",
      "3. su propiedad era de buen tamaño y en el centro de ella se encontraba la residencia norland park donde la manera tan digna en que habían vivido por muchas generaciones llegó a granjearles el respeto de todos los conocidos del lugar\n",
      "4. el último dueño de esta propiedad había sido un hombre soltero que alcanzó una muy avanzada edad y que durante gran parte de su existencia tuvo en su hermana una fiel compañera y ama de casa\n",
      "5. pero la muerte de ella ocurrida diez años antes que la suya produjo grandes alteraciones en su hogar\n"
     ]
    }
   ],
   "source": [
    "print(\"Cargando dataset...\")\n",
    "dataset = load_dataset(DATASET_NAME, split=DATASET_SPLIT, streaming=DATASET_STREAMING).take(DATASET_TAKE)\n",
    "sentences = [example['text'] for example in dataset if len(example['text'].split()) >= MIN_WORDS_PER_SENTENCE]\n",
    "\n",
    "print(f\"Total de oraciones cargadas: {len(sentences)}\")\n",
    "print(\"\\nEjemplos de oraciones:\")\n",
    "for i, sentence in enumerate(sentences[:5]):\n",
    "    print(f\"{i+1}. {sentence}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Tokenización y Creación del Vocabulario\n",
    "\n",
    "Se Tokenizan las oraciones y se crea el vocabulario con mapeo palabra→índice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulario: 30415 palabras\n",
      "\n",
      "Primeras 10 palabras del vocabulario:\n",
      "<OOV> → 1\n",
      "que → 2\n",
      "de → 3\n",
      "y → 4\n",
      "la → 5\n",
      "a → 6\n",
      "el → 7\n",
      "en → 8\n",
      "no → 9\n",
      "se → 10\n",
      "\n",
      "Ejemplo de tokenización:\n",
      "Oración: source wikisource librodot com sentido y sensibilidad jane austen capitulo i\n",
      "Secuencia: [8617, 15766, 15767, 11038, 447, 4, 2642, 204, 15768, 3947, 6156]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(oov_token=OOV_TOKEN)  # Token para palabras desconocidas\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "\n",
    "# Convertir frases a secuencias numéricas\n",
    "sequences = tokenizer.texts_to_sequences(sentences)\n",
    "\n",
    "# Tamaño del vocabulario\n",
    "vocab_size = len(tokenizer.word_index) + 1  # +1 por el padding (índice 0)\n",
    "print(f\"Vocabulario: {vocab_size} palabras\")\n",
    "\n",
    "print(\"\\nPrimeras 10 palabras del vocabulario:\")\n",
    "for i, (word, idx) in enumerate(list(tokenizer.word_index.items())[:10]):\n",
    "    print(f\"{word} → {idx}\")\n",
    "\n",
    "print(f\"\\nEjemplo de tokenización:\")\n",
    "example_sentence = sentences[0]\n",
    "example_sequence = sequences[0]\n",
    "print(f\"Oración: {example_sentence}\")\n",
    "print(f\"Secuencia: {example_sequence}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Creación del Conjunto de Entrenamiento (X, Y)\n",
    "\n",
    "Para cada secuencia `[w1, w2, ..., wn]`, se crean pares:\n",
    "- `(w1) → w2`\n",
    "- `(w1, w2) → w3`\n",
    "- `...`\n",
    "- `(w1, ..., wn-1) → wn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de secuencias de entrenamiento generadas: 475334\n",
      "\n",
      "Ejemplos de secuencias X → y:\n",
      "['source'] → wikisource\n",
      "['source', 'wikisource'] → librodot\n",
      "['source', 'wikisource', 'librodot'] → com\n",
      "['source', 'wikisource', 'librodot', 'com'] → sentido\n",
      "['source', 'wikisource', 'librodot', 'com', 'sentido'] → y\n"
     ]
    }
   ],
   "source": [
    "X = []  # Secuencias de entrada: [palabra1], [palabra1, palabra2], ...\n",
    "y = []  # Palabra siguiente (objetivo)\n",
    "\n",
    "for seq in sequences:\n",
    "    for i in range(len(seq) - 1):\n",
    "        X.append(seq[:i+1])    # Desde el inicio hasta la palabra actual\n",
    "        y.append(seq[i+1])     # La siguiente palabra\n",
    "\n",
    "print(f\"Total de secuencias de entrenamiento generadas: {len(X)}\")\n",
    "print(\"\\nEjemplos de secuencias X → y:\")\n",
    "for i in range(5):\n",
    "    # Convertir índices a palabras para mostrar\n",
    "    x_words = [tokenizer.index_word.get(idx, '<UNK>') for idx in X[i]]\n",
    "    y_word = tokenizer.index_word.get(y[i], '<UNK>')\n",
    "    print(f\"{x_words} → {y_word}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Padding y Truncado (MAX_LEN ≤ 50)\n",
    "\n",
    "Se Aplica padding a las secuencias y se trunca si la longitud máxima excede 50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longitud máxima encontrada: 321\n",
      "MAX_LEN aplicado (truncado a 50): 50\n",
      "\n",
      "Forma de X_padded: (475334, 50)\n",
      "Forma de y: (475334,)\n",
      "\n",
      "Ejemplo de X_padded (primeras 3 secuencias):\n",
      "[[    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0  8617]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "   8617 15766]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0  8617\n",
      "  15766 15767]]\n",
      "\n",
      "Ejemplo de y (primeras 10 etiquetas):\n",
      "[15766 15767 11038   447     4  2642   204 15768  3947  6156]\n"
     ]
    }
   ],
   "source": [
    "# Longitud máxima de las secuencias (con restricción MAX_LEN <= 50)\n",
    "raw_max_length = max([len(seq) for seq in X])\n",
    "MAX_LEN = min(50, raw_max_length)  # Aplicar restricción de máximo 50\n",
    "print(f\"Longitud máxima encontrada: {raw_max_length}\")\n",
    "print(f\"MAX_LEN aplicado (truncado a 50): {MAX_LEN}\")\n",
    "\n",
    "# Aplicar padding y truncado a las secuencias de entrada\n",
    "X_padded = pad_sequences(X, maxlen=MAX_LEN, padding=PADDING_TYPE, truncating='pre')\n",
    "y = np.array(y)  # Etiquetas: ya es un array 1D\n",
    "\n",
    "print(f\"\\nForma de X_padded: {X_padded.shape}\")  # (número de muestras, MAX_LEN)\n",
    "print(f\"Forma de y: {y.shape}\")\n",
    "print(\"\\nEjemplo de X_padded (primeras 3 secuencias):\")\n",
    "print(X_padded[:3])\n",
    "print(\"\\nEjemplo de y (primeras 10 etiquetas):\")\n",
    "print(y[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. División del Conjunto (Train/Test: 80%/20%)\n",
    "\n",
    "Se dividen los datos en conjuntos de entrenamiento y prueba usando `train_test_split`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "División del conjunto:\n",
      "X_train: (380267, 50), y_train: (380267,)\n",
      "X_test: (95067, 50), y_test: (95067,)\n",
      "\n",
      "Porcentajes:\n",
      "Entrenamiento: 80.0%\n",
      "Prueba: 20.0%\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_padded, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "print(f\"División del conjunto:\")\n",
    "print(f\"X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
    "print(f\"X_test: {X_test.shape}, y_test: {y_test.shape}\")\n",
    "print(f\"\\nPorcentajes:\")\n",
    "print(f\"Entrenamiento: {len(X_train)/(len(X_train)+len(X_test))*100:.1f}%\")\n",
    "print(f\"Prueba: {len(X_test)/(len(X_train)+len(X_test))*100:.1f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Construcción del Modelo LSTM/BiLSTM\n",
    "\n",
    "Se crea el modelo con arquitectura configurable (LSTM o BiLSTM) y se compila con `sparse_categorical_crossentropy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yenreh/anaconda3/envs/py310ia/lib/python3.10/site-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1758846730.092595  150397 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9683 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_hidden (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_hidden (\u001b[38;5;33mDense\u001b[0m)            │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output (\u001b[38;5;33mDense\u001b[0m)                  │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_model(vocab_size, max_length):\n",
    "    \"\"\"\n",
    "    Crea un modelo de lenguaje usando BiLSTM o LSTM según configuración.\n",
    "    \n",
    "    Args:\n",
    "        vocab_size (int): Tamaño del vocabulario\n",
    "        max_length (int): Longitud máxima de las secuencias\n",
    "    \n",
    "    Returns:\n",
    "        tensorflow.keras.Model: Modelo compilado\n",
    "    \"\"\"\n",
    "    model = Sequential([\n",
    "        Embedding(vocab_size, EMBEDDING_DIM, input_length=max_length, name='embedding'),\n",
    "        # Usar BiLSTM si está habilitado, sino LSTM unidireccional\n",
    "        Bidirectional(LSTM(LSTM_UNITS, name='lstm'), name='bidirectional_lstm') if USE_BIDIRECTIONAL \n",
    "        else LSTM(LSTM_UNITS, name='lstm'),\n",
    "        Dense(DENSE_UNITS, activation='relu', name='dense_hidden'),\n",
    "        Dense(vocab_size, activation='softmax', name='output')  # Probabilidades para cada palabra\n",
    "    ])\n",
    "    \n",
    "    # Configurar optimizador con tasa de aprendizaje personalizada\n",
    "    optimizer = Adam(learning_rate=LEARNING_RATE)\n",
    "    \n",
    "    # Usar sparse_categorical_crossentropy (NO necesita one-hot encoding)\n",
    "    model.compile(\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        optimizer=optimizer,\n",
    "        metrics=['accuracy', 'sparse_top_k_categorical_accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = create_model(vocab_size, MAX_LEN)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Entrenamiento del Modelo con Early Stopping\n",
    "\n",
    "Se entrena el modelo con Early Stopping para prevenir overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando el modelo LSTM...\n",
      "Arquitectura: 300D embedding → LSTM(128) → Dense(128) → Softmax(30415)\n",
      "Parámetros de entrenamiento: 30 epochs, batch_size=32, lr=0.001\n",
      "Early Stopping habilitado: val_loss con patience=5\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-25 19:32:11.808522: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:473] Loaded cuDNN version 91300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m9507/9507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 18ms/step - accuracy: 0.0777 - loss: 6.6866 - sparse_top_k_categorical_accuracy: 0.2336 - val_accuracy: 0.0947 - val_loss: 6.4900 - val_sparse_top_k_categorical_accuracy: 0.2523\n",
      "Epoch 2/30\n",
      "\u001b[1m9507/9507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 18ms/step - accuracy: 0.1114 - loss: 6.0687 - sparse_top_k_categorical_accuracy: 0.2697 - val_accuracy: 0.1135 - val_loss: 6.3238 - val_sparse_top_k_categorical_accuracy: 0.2730\n",
      "Epoch 3/30\n",
      "\u001b[1m9507/9507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 18ms/step - accuracy: 0.1302 - loss: 5.7086 - sparse_top_k_categorical_accuracy: 0.2893 - val_accuracy: 0.1186 - val_loss: 6.3299 - val_sparse_top_k_categorical_accuracy: 0.2813\n",
      "Epoch 4/30\n",
      "\u001b[1m9505/9507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.1451 - loss: 5.4439 - sparse_top_k_categorical_accuracy: 0.3045"
     ]
    }
   ],
   "source": [
    "# Configurar Early Stopping\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',     # Métrica a monitorear\n",
    "    patience=5,             # Número de épocas sin mejora antes de parar\n",
    "    restore_best_weights=True,  # Restaurar los mejores pesos\n",
    "    verbose=1               # Mostrar información cuando se pare\n",
    ")\n",
    "\n",
    "print(f\"Entrenando el modelo {'BiLSTM' if USE_BIDIRECTIONAL else 'LSTM'}...\")\n",
    "print(f\"Arquitectura: {EMBEDDING_DIM}D embedding → {'Bi-' if USE_BIDIRECTIONAL else ''}LSTM({LSTM_UNITS}) → Dense({DENSE_UNITS}) → Softmax({vocab_size})\")\n",
    "print(f\"Parámetros de entrenamiento: {EPOCHS} epochs, batch_size={BATCH_SIZE}, lr={LEARNING_RATE}\")\n",
    "print(\"Early Stopping habilitado: val_loss con patience=5\")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,  # Usar conjuntos de entrenamiento divididos\n",
    "    epochs=EPOCHS,\n",
    "    verbose=VERBOSE_TRAINING,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_split=VALIDATION_SPLIT,  # Usar datos de entrenamiento para validación\n",
    "    shuffle=True,\n",
    "    callbacks=[early_stopping]  # Agregar Early Stopping\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Cálculo de la Perplejidad\n",
    "\n",
    "Se immplementan las funciones para calcular la perplejidad.\n",
    "\n",
    "**Fórmula:** `perplexity = exp(-average_log_likelihood)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_perplexity(model, X_test, y_test, batch_size=32):\n",
    "    \"\"\"\n",
    "    Calcula la perplejidad del modelo en el conjunto de prueba usando CPU.\n",
    "\n",
    "    Args:\n",
    "        model: Modelo entrenado\n",
    "        X_test: Conjunto de prueba de entrada\n",
    "        y_test: Conjunto de prueba de salida (etiquetas verdaderas)\n",
    "        batch_size: Tamaño de batch para predict\n",
    "    \n",
    "    Returns:\n",
    "        float: Valor de perplejidad\n",
    "    \"\"\"\n",
    "    # Forzar CPU para evitar problemas de memoria en GPU\n",
    "    with tf.device(\"/CPU:0\"):\n",
    "        predictions = model.predict(X_test, verbose=0, batch_size=batch_size)\n",
    "\n",
    "    # Calcular log-likelihood promedio\n",
    "    log_likelihoods = []\n",
    "    for i in range(len(y_test)):\n",
    "        true_word_idx = y_test[i]\n",
    "        predicted_prob = predictions[i][true_word_idx]\n",
    "        predicted_prob = max(predicted_prob, 1e-10)  # evitar log(0)\n",
    "        log_likelihoods.append(np.log(predicted_prob))\n",
    "\n",
    "    average_log_likelihood = np.mean(log_likelihoods)\n",
    "    perplexity = np.exp(-average_log_likelihood)\n",
    "\n",
    "    return perplexity\n",
    "\n",
    "def interpret_perplexity(perplexity_value):\n",
    "    \"\"\"\n",
    "    Interpreta el valor de perplejidad según rangos comunes.\n",
    "    \n",
    "    Args:\n",
    "        perplexity_value (float): Valor de perplejidad calculado\n",
    "        \n",
    "    Returns:\n",
    "        str: Interpretación del valor\n",
    "    \"\"\"\n",
    "    if perplexity_value < 10:\n",
    "        return \"Excelente\"\n",
    "    elif perplexity_value < 50:\n",
    "        return \"Muy bueno\"\n",
    "    elif perplexity_value < 100:\n",
    "        return \"Bueno\"\n",
    "    elif perplexity_value < 200:\n",
    "        return \"Aceptable\"\n",
    "    elif perplexity_value < 500:\n",
    "        return \"Regular\"\n",
    "    else:\n",
    "        return \"Pobre\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_experiment_results(history, model, perplexity, vocab_size, X_train, X_test, MAX_LEN):\n",
    "    \"\"\"\n",
    "    Guarda los resultados del experimento en un archivo JSON para llevar historial.\n",
    "    \n",
    "    Args:\n",
    "        history: Historial del entrenamiento\n",
    "        model: Modelo entrenado\n",
    "        perplexity: Valor de perplejidad calculado\n",
    "        vocab_size: Tamaño del vocabulario\n",
    "        X_train, X_test: Conjuntos de datos para obtener tamaños\n",
    "        MAX_LEN: Longitud máxima de secuencia\n",
    "    \"\"\"\n",
    "    # Preparar datos del experimento\n",
    "    experiment_data = {\n",
    "        \"timestamp\": datetime.datetime.now().isoformat(),\n",
    "        \"configuration\": {\n",
    "            \"model_type\": \"BiLSTM\" if USE_BIDIRECTIONAL else \"LSTM\",\n",
    "            \"embedding_dim\": EMBEDDING_DIM,\n",
    "            \"lstm_units\": LSTM_UNITS,\n",
    "            \"dense_units\": DENSE_UNITS,\n",
    "            \"epochs\": EPOCHS,\n",
    "            \"batch_size\": BATCH_SIZE,\n",
    "            \"learning_rate\": LEARNING_RATE,\n",
    "            \"dataset_take\": DATASET_TAKE,\n",
    "            \"max_len\": MAX_LEN,\n",
    "            \"padding_type\": PADDING_TYPE,\n",
    "            \"min_words_per_sentence\": MIN_WORDS_PER_SENTENCE,\n",
    "            \"gpu_used\": len(tf.config.list_physical_devices('GPU')) > 0 \n",
    "        },\n",
    "        \"dataset_info\": {\n",
    "            \"vocab_size\": int(vocab_size),\n",
    "            \"train_samples\": int(len(X_train)),\n",
    "            \"test_samples\": int(len(X_test)),\n",
    "            \"dataset_name\": DATASET_NAME\n",
    "        },\n",
    "        \"training_results\": {\n",
    "            \"final_train_loss\": float(history.history['loss'][-1]),\n",
    "            \"final_train_accuracy\": float(history.history['accuracy'][-1]),\n",
    "            \"final_val_loss\": float(history.history.get('val_loss', [-1])[-1]) if 'val_loss' in history.history else None,\n",
    "            \"final_val_accuracy\": float(history.history.get('val_accuracy', [-1])[-1]) if 'val_accuracy' in history.history else None,\n",
    "            \"epochs_trained\": len(history.history['loss']),\n",
    "            \"model_parameters\": int(model.count_params())\n",
    "        },\n",
    "        \"evaluation_metrics\": {\n",
    "            \"perplexity\": float(perplexity),\n",
    "            \"perplexity_interpretation\": interpret_perplexity(perplexity)\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Nombre del archivo de historial\n",
    "    results_file = \"experiment_history.json\"\n",
    "    \n",
    "    # Cargar historial existente o crear uno nuevo\n",
    "    if os.path.exists(results_file):\n",
    "        try:\n",
    "            with open(results_file, 'r', encoding='utf-8') as f:\n",
    "                history_data = json.load(f)\n",
    "        except:\n",
    "            history_data = {\"experiments\": []}\n",
    "    else:\n",
    "        history_data = {\"experiments\": []}\n",
    "    \n",
    "    # Agregar nuevo experimento\n",
    "    experiment_data[\"experiment_id\"] = len(history_data[\"experiments\"]) + 1\n",
    "    history_data[\"experiments\"].append(experiment_data)\n",
    "    \n",
    "    # Guardar archivo actualizado\n",
    "    with open(results_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(history_data, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    print(f\"Experimento #{experiment_data['experiment_id']} guardado en {results_file}\")\n",
    "    return results_file\n",
    "\n",
    "print(\"Función de guardado de experimentos definida exitosamente!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Evaluación Completa del Modelo\n",
    "\n",
    "Se evalua el rendimiento del modelo incluyendo perplejidad y métricas estándar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_performance(history, model, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Muestra métricas de rendimiento del modelo durante el entrenamiento y evaluación.\n",
    "    \"\"\"\n",
    "    print(\"\\n=== MÉTRICAS DE ENTRENAMIENTO ===\")\n",
    "    final_loss = history.history['loss'][-1]\n",
    "    final_accuracy = history.history['accuracy'][-1]\n",
    "    \n",
    "    if 'val_loss' in history.history:\n",
    "        final_val_loss = history.history['val_loss'][-1]\n",
    "        final_val_accuracy = history.history['val_accuracy'][-1]\n",
    "        print(f\"Loss final: {final_loss:.4f} | Val Loss: {final_val_loss:.4f}\")\n",
    "        print(f\"Accuracy final: {final_accuracy:.4f} | Val Accuracy: {final_val_accuracy:.4f}\")\n",
    "    else:\n",
    "        print(f\"Loss final: {final_loss:.4f}\")\n",
    "        print(f\"Accuracy final: {final_accuracy:.4f}\")\n",
    "    \n",
    "    # Evaluar en conjunto de prueba\n",
    "    print(\"\\n=== EVALUACIÓN EN CONJUNTO DE PRUEBA ===\")\n",
    "    test_results = model.evaluate(X_test, y_test, verbose=0)\n",
    "    test_loss = test_results[0]\n",
    "    test_accuracy = test_results[1]\n",
    "    print(f\"Test Loss: {test_loss:.4f}\")\n",
    "    print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "    \n",
    "    # Si hay métricas adicionales, mostrarlas también\n",
    "    if len(test_results) > 2:\n",
    "        test_top_k_accuracy = test_results[2]\n",
    "        print(f\"Test Top-K Accuracy: {test_top_k_accuracy:.4f}\")\n",
    "    \n",
    "    # Calcular perplejidad\n",
    "    print(\"\\n=== CÁLCULO DE PERPLEJIDAD ===\")\n",
    "    perplexity = calculate_perplexity(model, X_test, y_test)\n",
    "    interpretation = interpret_perplexity(perplexity)\n",
    "    \n",
    "    print(f\"Perplejidad en conjunto de prueba: {perplexity:.2f}\")\n",
    "    print(f\"Interpretación: {interpretation}\")\n",
    "    \n",
    "    # Tabla de interpretación\n",
    "    print(\"\\n=== TABLA DE INTERPRETACIÓN DE PERPLEJIDAD ===\")\n",
    "    print(\"< 10:     Excelente\")\n",
    "    print(\"10-50:    Muy bueno\") \n",
    "    print(\"50-100:   Bueno\")\n",
    "    print(\"100-200:  Aceptable\")\n",
    "    print(\"200-500:  Regular\")\n",
    "    print(\"> 500:    Pobre\")\n",
    "    \n",
    "    # Guardar resultados del experimento automáticamente\n",
    "    print(\"\\n=== GUARDANDO RESULTADOS DEL EXPERIMENTO ===\")\n",
    "    try:\n",
    "        save_experiment_results(history, model, perplexity, vocab_size, X_train, X_test, MAX_LEN)\n",
    "    except Exception as e:\n",
    "        print(f\"Error al guardar experimento: {e}\")\n",
    "    \n",
    "    return perplexity\n",
    "\n",
    "# Evaluar rendimiento (incluyendo perplejidad)\n",
    "perplexity = evaluate_model_performance(history, model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Predicción de la Próxima Palabra\n",
    "\n",
    "Se implementa la función `predict_next_word` para predecir la siguiente palabra dada una secuencia de entrada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next_word(model, tokenizer, sentence, max_length, top_k=1):\n",
    "    \"\"\"\n",
    "    Predice la(s) palabra(s) siguiente(s) dada una oración en español.\n",
    "    \n",
    "    Args:\n",
    "        model: Modelo entrenado\n",
    "        tokenizer: Tokenizador ajustado\n",
    "        sentence (str): Oración de entrada\n",
    "        max_length (int): Longitud máxima de secuencia\n",
    "        top_k (int): Número de predicciones top a retornar\n",
    "    \n",
    "    Returns:\n",
    "        str o list: Palabra predicha (top_k=1) o lista de predicciones (top_k>1)\n",
    "    \"\"\"\n",
    "    # Tokenizar la oración\n",
    "    sequence = tokenizer.texts_to_sequences([sentence])[0]\n",
    "\n",
    "    if len(sequence) == 0:\n",
    "        return \"<no_reconocido>\" if top_k == 1 else [\"<no_reconocido>\"]\n",
    "\n",
    "    # Aplicar padding usando el mismo tipo configurado\n",
    "    sequence_padded = pad_sequences([sequence], maxlen=max_length, padding=PADDING_TYPE, truncating='pre')\n",
    "\n",
    "    # Predecir probabilidades\n",
    "    prediction = model.predict(sequence_padded, verbose=VERBOSE_PREDICTION)\n",
    "    \n",
    "    if top_k == 1:\n",
    "        # Retornar solo la predicción más probable\n",
    "        predicted_idx = np.argmax(prediction[0])\n",
    "        predicted_word = tokenizer.index_word.get(predicted_idx, \"<desconocido>\")\n",
    "        return predicted_word\n",
    "    else:\n",
    "        # Retornar las top_k predicciones más probables\n",
    "        top_indices = np.argsort(prediction[0])[-top_k:][::-1]\n",
    "        predictions = []\n",
    "        for idx in top_indices:\n",
    "            word = tokenizer.index_word.get(idx, \"<desconocido>\")\n",
    "            prob = prediction[0][idx]\n",
    "            predictions.append((word, prob))\n",
    "        return predictions\n",
    "\n",
    "def generate_text(model, tokenizer, seed_text, max_length, num_words_to_generate=10):\n",
    "    \"\"\"\n",
    "    Genera texto continuando desde un texto semilla.\n",
    "    \n",
    "    Args:\n",
    "        model: Modelo entrenado\n",
    "        tokenizer: Tokenizador ajustado\n",
    "        seed_text (str): Texto inicial\n",
    "        max_length (int): Longitud máxima de secuencia\n",
    "        num_words_to_generate (int): Número de palabras a generar\n",
    "    \n",
    "    Returns:\n",
    "        str: Texto generado\n",
    "    \"\"\"\n",
    "    generated_text = seed_text\n",
    "    \n",
    "    for _ in range(num_words_to_generate):\n",
    "        next_word = predict_next_word(model, tokenizer, generated_text, max_length)\n",
    "        if next_word in [\"<no_reconocido>\", \"<desconocido>\"]:\n",
    "            break\n",
    "        generated_text += \" \" + next_word\n",
    "    \n",
    "    return generated_text\n",
    "\n",
    "print(\"Funciones de predicción definidas exitosamente!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Pruebas de Predicción de Siguiente Palabra\n",
    "\n",
    "Se prueba el modelo con casos de prueba en español."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Casos de prueba para predicción de siguiente palabra\n",
    "test_cases = [\n",
    "    \"el gato se sentó en la\",\n",
    "    \"los estudiantes abrieron sus\",\n",
    "    \"la maestra escribió en el\",\n",
    "    \"el niño jugó con un\",\n",
    "    \"el pájaro voló sobre el\",\n",
    "    \"el sol se elevó en el\",\n",
    "    \"la casa tiene una\",\n",
    "    \"me gusta comer\",\n",
    "    \"vamos a la\"\n",
    "]\n",
    "\n",
    "print(f\"=== PREDICCIÓN DE SIGUIENTE PALABRA ({'BiLSTM' if USE_BIDIRECTIONAL else 'LSTM'}) ===\")\n",
    "for sentence in test_cases:\n",
    "    next_word = predict_next_word(model, tokenizer, sentence, MAX_LEN)\n",
    "    print(f\"'{sentence}' → '{next_word}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Predicciones Top-K\n",
    "\n",
    "Se muestran las K(3) predicciones más probables para algunos casos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicciones top-k para algunos casos\n",
    "print(f\"=== TOP-3 PREDICCIONES ===\")\n",
    "for sentence in test_cases[:3]:\n",
    "    top_predictions = predict_next_word(model, tokenizer, sentence, MAX_LEN, top_k=3)\n",
    "    print(f\"'{sentence}':\")\n",
    "    for i, (word, prob) in enumerate(top_predictions, 1):\n",
    "        print(f\"  {i}. '{word}' (probabilidad: {prob:.4f})\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Generación de Texto\n",
    "\n",
    "Se genera texto continuando desde un texto semilla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generación de texto\n",
    "print(f\"=== GENERACIÓN DE TEXTO ===\")\n",
    "seed_texts = [\n",
    "    \"el perro\",\n",
    "    \"los estudiantes\",\n",
    "    \"en la casa\"\n",
    "]\n",
    "\n",
    "for seed in seed_texts:\n",
    "    generated = generate_text(model, tokenizer, seed, MAX_LEN, num_words_to_generate=8)\n",
    "    print(f\"Semilla: '{seed}'\")\n",
    "    print(f\"Generado: '{generated}'\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. Resumen Final del Modelo\n",
    "\n",
    "Se muestra un resumen completo de las características y rendimiento del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== RESUMEN DEL MODELO ===\")\n",
    "print(f\"Vocabulario: {vocab_size:,} palabras\")\n",
    "print(f\"Secuencias de entrenamiento: {len(X_train):,}\")\n",
    "print(f\"Secuencias de prueba: {len(X_test):,}\")\n",
    "print(f\"Longitud máxima de secuencia (MAX_LEN): {MAX_LEN}\")\n",
    "print(f\"Arquitectura: {'BiLSTM' if USE_BIDIRECTIONAL else 'LSTM'}\")\n",
    "print(f\"Parámetros del modelo: {model.count_params():,}\")\n",
    "print(f\"Dataset utilizado: {DATASET_NAME} (primeras {DATASET_TAKE:,} muestras)\")\n",
    "print(f\"Perplejidad final: {perplexity:.2f} ({interpret_perplexity(perplexity)})\")\n",
    "\n",
    "print(\"\\n=== COMPONENTES IMPLEMENTADOS ===\")\n",
    "components = [\n",
    "    \"Carga del Dataset (spanish_billion_words_clean)\",\n",
    "    \"Tokenización y Creación del Vocabulario\", \n",
    "    \"Creación del Conjunto de Entrenamiento (X, Y)\",\n",
    "    \"Padding y Truncado (MAX_LEN ≤ 50)\",\n",
    "    \"División del Conjunto (Train/Test 80%/20%)\",\n",
    "    \"Construcción del Modelo LSTM/BiLSTM\",\n",
    "    \"Entrenamiento con Early Stopping\",\n",
    "    \"Cálculo de la Perplejidad\",\n",
    "    \"Predicción de la Próxima Palabra\",\n",
    "    \"Uso de sparse_categorical_crossentropy\"\n",
    "]\n",
    "\n",
    "for component in components:\n",
    "    print(component)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Conclusiones\n",
    "\n",
    "Este notebook implementa completamente los requerimientos de la Tarea 1:\n",
    "\n",
    "1. **Dataset**: Se utilizó `spanish_billion_words_clean` de Hugging Face\n",
    "2. **Tokenización**: Se Implementó con vocabulario único y mapeo palabra↔índice\n",
    "3. **Preparación de datos**: Secuencias (X,Y) con padding/truncado (MAX_LEN≤50)\n",
    "4. **División**: 80% entrenamiento / 20% prueba con `train_test_split`\n",
    "5. **Modelo**: Arquitectura LSTM/BiLSTM configurable con embedding\n",
    "6. **Entrenamiento**: Con Early Stopping y `sparse_categorical_crossentropy`\n",
    "7. **Evaluación**: Perplejidad calculada \n",
    "8. **Predicción**: Función `predict_next_word`\n",
    "\n",
    "El modelo puede alternar entre LSTM y BiLSTM simplemente cambiando `USE_BIDIRECTIONAL=True/False` en los parámetros globales.\n",
    "\n",
    "**Parámetros recomendados para experimentación:**\n",
    "- EMBEDDING_DIM: 100-300\n",
    "- LSTM_UNITS: 64-128\n",
    "- DENSE_UNITS: 64-128\n",
    "- LEARNING_RATE: 0.001-0.01\n",
    "- BATCH_SIZE: 8-32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16. Historial de Experimentos\n",
    "\n",
    "Este bloque muestra todos los experimentos realizados, permitiendo comparar diferentes configuraciones y resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_display_experiment_history():\n",
    "    \"\"\"\n",
    "    Carga y muestra el historial completo de experimentos con comparaciones.\n",
    "    \"\"\"\n",
    "    results_file = \"experiment_history.json\"\n",
    "    \n",
    "    if not os.path.exists(results_file):\n",
    "        print(\"No hay historial de experimentos disponible.\")\n",
    "        print(\"Ejecuta el notebook completo para generar el primer experimento.\")\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        with open(results_file, 'r', encoding='utf-8') as f:\n",
    "            history_data = json.load(f)\n",
    "        \n",
    "        experiments = history_data.get(\"experiments\", [])\n",
    "        \n",
    "        if not experiments:\n",
    "            print(\"No hay experimentos en el historial.\")\n",
    "            return\n",
    "        \n",
    "        print(f\"HISTORIAL DE EXPERIMENTOS ({len(experiments)} experimentos)\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        # Mostrar resumen de todos los experimentos\n",
    "        print(\"\\n🔍 RESUMEN COMPARATIVO:\")\n",
    "        print(f\"{'ID':<3} {'Modelo':<7} {'Emb':<4} {'LSTM':<5} {'Dense':<6} {'Épocas':<7} {'Perplejidad':<12} {'Interp.':<12} {'GPU':<12}\")\n",
    "        print(\"-\" * 85)\n",
    "        \n",
    "        for exp in experiments:\n",
    "            config = exp['configuration']\n",
    "            metrics = exp['evaluation_metrics']\n",
    "            training = exp['training_results']\n",
    "            \n",
    "            print(f\"{exp['experiment_id']:<3} \"\n",
    "                  f\"{config['model_type']:<7} \"\n",
    "                  f\"{config['embedding_dim']:<4} \"\n",
    "                  f\"{config['lstm_units']:<5} \"\n",
    "                  f\"{config['dense_units']:<6} \"\n",
    "                  f\"{training['epochs_trained']:<7} \"\n",
    "                  f\"{metrics['perplexity']:<12.2f} \"\n",
    "                  f\"{metrics['perplexity_interpretation']:<12} \"\n",
    "                  f\"{'Sí' if config['gpu_used'] else 'No':<12}\"  \n",
    "                )\n",
    "        \n",
    "        # Encontrar mejores y peores experimentos\n",
    "        best_exp = min(experiments, key=lambda x: x['evaluation_metrics']['perplexity'])\n",
    "        worst_exp = max(experiments, key=lambda x: x['evaluation_metrics']['perplexity'])\n",
    "        \n",
    "        print(f\"\\n MEJOR EXPERIMENTO (menor perplejidad):\")\n",
    "        print(f\"   ID #{best_exp['experiment_id']}: {best_exp['configuration']['model_type']} \"\n",
    "              f\"con perplejidad {best_exp['evaluation_metrics']['perplexity']:.2f} \"\n",
    "              f\"({best_exp['evaluation_metrics']['perplexity_interpretation']})\")\n",
    "        \n",
    "        print(f\"\\n PEOR EXPERIMENTO (mayor perplejidad):\")\n",
    "        print(f\"   ID #{worst_exp['experiment_id']}: {worst_exp['configuration']['model_type']} \"\n",
    "              f\"con perplejidad {worst_exp['evaluation_metrics']['perplexity']:.2f} \"\n",
    "              f\"({worst_exp['evaluation_metrics']['perplexity_interpretation']})\")\n",
    "        \n",
    "        # Mostrar estadísticas generales\n",
    "        all_perplexities = [exp['evaluation_metrics']['perplexity'] for exp in experiments]\n",
    "        avg_perplexity = sum(all_perplexities) / len(all_perplexities)\n",
    "        \n",
    "        print(f\"\\n ESTADÍSTICAS GENERALES:\")\n",
    "        print(f\"   Perplejidad promedio: {avg_perplexity:.2f}\")\n",
    "        print(f\"   Rango de perplejidad: {min(all_perplexities):.2f} - {max(all_perplexities):.2f}\")\n",
    "        \n",
    "        # Contar modelos por tipo\n",
    "        lstm_count = sum(1 for exp in experiments if exp['configuration']['model_type'] == 'LSTM')\n",
    "        bilstm_count = sum(1 for exp in experiments if exp['configuration']['model_type'] == 'BiLSTM')\n",
    "        \n",
    "        print(f\"   Experimentos LSTM: {lstm_count}\")\n",
    "        print(f\"   Experimentos BiLSTM: {bilstm_count}\")\n",
    "        \n",
    "        # Mostrar detalles del último experimento\n",
    "        if experiments:\n",
    "            last_exp = experiments[-1]\n",
    "            print(f\"\\n ÚLTIMO EXPERIMENTO (ID #{last_exp['experiment_id']}):\")\n",
    "            # print(f\"   Fecha: {datetime.datetime.fromisoformat(last_exp['timestamp']).strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "            print(f\"   Modelo: {last_exp['configuration']['model_type']}\")\n",
    "            print(f\"   Configuración: Emb={last_exp['configuration']['embedding_dim']}, \"\n",
    "                  f\"LSTM={last_exp['configuration']['lstm_units']}, \"\n",
    "                  f\"Dense={last_exp['configuration']['dense_units']}\")\n",
    "            print(f\"   Entrenamiento: {last_exp['training_results']['epochs_trained']} épocas, \"\n",
    "                  f\"batch_size={last_exp['configuration']['batch_size']}\")\n",
    "            print(f\"   Resultados: Perplejidad={last_exp['evaluation_metrics']['perplexity']:.2f} \"\n",
    "                  f\"({last_exp['evaluation_metrics']['perplexity_interpretation']})\")\n",
    "            print(f\"   Accuracy final: {last_exp['training_results']['final_train_accuracy']:.4f}\")\n",
    "            if last_exp['training_results']['final_val_accuracy']:\n",
    "                print(f\"   Val Accuracy: {last_exp['training_results']['final_val_accuracy']:.4f}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\" Error al cargar historial: {e}\")\n",
    "\n",
    "def show_experiment_details(experiment_id):\n",
    "    \"\"\"\n",
    "    Muestra detalles completos de un experimento específico.\n",
    "    \n",
    "    Args:\n",
    "        experiment_id (int): ID del experimento a mostrar\n",
    "    \"\"\"\n",
    "    results_file = \"experiment_history.json\"\n",
    "    \n",
    "    if not os.path.exists(results_file):\n",
    "        print(\"No hay historial de experimentos disponible.\")\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        with open(results_file, 'r', encoding='utf-8') as f:\n",
    "            history_data = json.load(f)\n",
    "        \n",
    "        experiments = history_data.get(\"experiments\", [])\n",
    "        experiment = next((exp for exp in experiments if exp['experiment_id'] == experiment_id), None)\n",
    "        \n",
    "        if not experiment:\n",
    "            print(f\"No se encontró experimento con ID #{experiment_id}\")\n",
    "            return\n",
    "        \n",
    "        print(f\"DETALLES DEL EXPERIMENTO #{experiment_id}\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        #timestamp = datetime.datetime.fromisoformat(experiment['timestamp'])\n",
    "        #print(f\"Fecha: {timestamp.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "        \n",
    "        config = experiment['configuration']\n",
    "        print(f\"\\n CONFIGURACIÓN:\")\n",
    "        print(f\"   Modelo: {config['model_type']}\")\n",
    "        print(f\"   Embedding: {config['embedding_dim']} dimensiones\")\n",
    "        print(f\"   LSTM Units: {config['lstm_units']}\")\n",
    "        print(f\"   Dense Units: {config['dense_units']}\")\n",
    "        print(f\"   Épocas configuradas: {config['epochs']}\")\n",
    "        print(f\"   Batch Size: {config['batch_size']}\")\n",
    "        print(f\"   Learning Rate: {config['learning_rate']}\")\n",
    "        print(f\"   Dataset samples: {config['dataset_take']:,}\")\n",
    "        print(f\"   MAX_LEN: {config['max_len']}\")\n",
    "        \n",
    "        dataset = experiment['dataset_info']\n",
    "        print(f\"\\n DATOS:\")\n",
    "        print(f\"   Vocabulario: {dataset['vocab_size']:,} palabras\")\n",
    "        print(f\"   Entrenamiento: {dataset['train_samples']:,} muestras\")\n",
    "        print(f\"   Prueba: {dataset['test_samples']:,} muestras\")\n",
    "        \n",
    "        training = experiment['training_results']\n",
    "        print(f\"\\n ENTRENAMIENTO:\")\n",
    "        print(f\"   Épocas entrenadas: {training['epochs_trained']}\")\n",
    "        print(f\"   Loss final: {training['final_train_loss']:.4f}\")\n",
    "        print(f\"   Accuracy final: {training['final_train_accuracy']:.4f}\")\n",
    "        if training['final_val_loss']:\n",
    "            print(f\"   Validation Loss: {training['final_val_loss']:.4f}\")\n",
    "            print(f\"   Validation Accuracy: {training['final_val_accuracy']:.4f}\")\n",
    "        print(f\"   Parámetros del modelo: {training['model_parameters']:,}\")\n",
    "        \n",
    "        metrics = experiment['evaluation_metrics']\n",
    "        print(f\"\\n EVALUACIÓN:\")\n",
    "        print(f\"   Perplejidad: {metrics['perplexity']:.2f}\")\n",
    "        print(f\"   Interpretación: {metrics['perplexity_interpretation']}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error al mostrar detalles: {e}\")\n",
    "\n",
    "# Cargar y mostrar historial\n",
    "load_and_display_experiment_history()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310ia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
